{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack Overflow Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem and Data insights\n",
    "\n",
    "### Task : Given a query deliver the most relevant or similar answers to that query\n",
    "\n",
    "### Using the data from :https://archive.org/download/stackexchange\n",
    "\n",
    "### Data Form : XML Files\n",
    "\n",
    "### features: \n",
    "* Title: It contains the Title of the Post\n",
    "* Question_body : It contains the Question of the Post\n",
    "* Answer_body : It contains the answer of the Post\n",
    "\n",
    "### Methodology\n",
    "#### We will be using the Elastic Search Which will be containerized in a Docker Instance.\n",
    "#### We will be executing the series of commands to pull and run the elastic search image from the docker repository.\n",
    "#### commands:\n",
    "* docker pull docker.elastic.co/elasticsearch/elasticsearch:7.9.3\n",
    "* docker run -p 9200:9200 -p 9200:9300 -e \"discovery.type=single-node\" docker.elastic.co/elasticsearch/elasticsearch:7.9.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Some Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "import xml.etree.ElementTree as parser\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_text_dictionary = {}\n",
    "temp = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(q):\n",
    "    cleantext = BeautifulSoup(q, \"lxml\").text\n",
    "    return cleantext.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterq(tree , cat):\n",
    "    for i in tree.iter('row'):\n",
    "        point_dictionary = i.attrib\n",
    "        # for questions and titles\n",
    "        if point_dictionary['PostTypeId'] == '1':\n",
    "            \n",
    "            identity = cat + \"_\" + point_dictionary['Id']\n",
    "            title = point_dictionary['Title']\n",
    "            question = point_dictionary['Body']\n",
    "            \n",
    "            if total_text_dictionary.get(identity, None) == None:\n",
    "                total_text_dictionary[identity] = []\n",
    "            total_text_dictionary[identity].append(preprocess(title))\n",
    "            total_text_dictionary[identity].append(preprocess(question))\n",
    "            \n",
    "def itera(tree , cat):\n",
    "    for i in tree.iter('row'):\n",
    "        point_dictionary = i.attrib\n",
    "        # for answers\n",
    "        if point_dictionary['PostTypeId'] == '2':\n",
    "            identity = cat + \"_\" + point_dictionary['ParentId']\n",
    "            answers = point_dictionary['Body']\n",
    "            total_text_dictionary[identity].append(preprocess(answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 ) Collecting the Data from different Files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree=parser.parse('D:/data/math.meta.stackexchange.com/Posts.xml').getroot()\n",
    "iterq(tree , 'math')\n",
    "itera(tree , 'math')\n",
    "\n",
    "tree=parser.parse('D:/data/ai.stackexchange.com/Posts.xml').getroot()\n",
    "iterq(tree , 'ai')\n",
    "itera(tree , 'ai')\n",
    "\n",
    "tree=parser.parse('D:/data/datascience.stackexchange.com/Posts.xml').getroot()\n",
    "iterq(tree , 'datascience')\n",
    "itera(tree , 'datascience')\n",
    "\n",
    "tree=parser.parse('D:/data/cs.stackexchange.com/Posts.xml').getroot()\n",
    "iterq(tree , 'cs')\n",
    "itera(tree , 'cs')\n",
    "\n",
    "tree=parser.parse('D:/data/softwareengineering.stackexchange.com/Posts.xml').getroot()\n",
    "iterq(tree , 'soft_eng')\n",
    "itera(tree , 'soft_eng')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2) Saving the Dictionary File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text_dictionary.pickle', 'wb') as temp_var:\n",
    "    pickle.dump(total_text_dictionary, temp_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3) Loading the Dictionary File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text_dictionary.pickle', 'rb') as temp_var:\n",
    "    total_text_dictionary = pickle.load(temp_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.) Modelling Using the Universal-sentence-encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 ) Loading the Universal-Sentence-encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "embed = tf.keras.models.load_model('universal-sentence-encoder_4')\n",
    "def make_vector(query):\n",
    "    embeddings = embed([query])\n",
    "    vector = []\n",
    "    for i in embeddings[0]:\n",
    "        vector.append(float(i))\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) Connecting to the Elastic Search Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to ES!\n"
     ]
    }
   ],
   "source": [
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n",
    "if es.ping():\n",
    "    print('Connected to ES!')\n",
    "else:\n",
    "    print('Could not connect!')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3) Defining the Structure of the Elastic Search Database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure = {\"mappings\": {\n",
    "      \"properties\": {\n",
    "            \"total_texts\": {\n",
    "              \"type\": \"text\"\n",
    "            },\n",
    "            \"total_vectors\": {\n",
    "                  \"type\": \"dense_vector\",\n",
    "                \"dims\": 512\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "ret = es.indices.create(index='database', ignore=400, body=structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4) Indexing of the data into the elastic search or feeding the data to the elastic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(total_text_dictionary.items()):\n",
    "    doc_id = i[0]\n",
    "    total_text = \" \".join(i[1])\n",
    "    point = {\"total_texts\":total_text ,\"total_vectors\" : make_vector(total_text)}\n",
    "    res = es.index(index=\"database\", id=doc_id, body=point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5) Defining the Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    def norm_list(lis):\n",
    "        scores = [x[0] for x in lis]\n",
    "        ma = max(scores)\n",
    "        mi = min(scores)\n",
    "        for i in range(len(lis)):\n",
    "            lis[i][0] = (lis[i][0] - mi)/(ma - mi)\n",
    "        return lis\n",
    "    \n",
    "    request={\n",
    "            'query':{ 'match':{\"total_texts\":query } }\n",
    "            }\n",
    "\n",
    "    res= es.search(index='database',body=request)\n",
    "    l1 = []\n",
    "    for hit in res['hits']['hits']:\n",
    "        l1.append([hit['_score'] , hit['_id']])\n",
    "# change the cosine similarity to euclidean distance\n",
    "\n",
    "    query_vector = make_vector(query)\n",
    "    request = {\"query\" : {\n",
    "                \"script_score\" : {\n",
    "                    \"query\" : {\n",
    "                        \"match_all\": {}\n",
    "                    },\n",
    "                    \"script\" : {\n",
    "                        \"source\": \"cosineSimilarity(params.query_vector, 'total_vectors') + 1.0\",\n",
    "                        \"params\": {\"query_vector\": query_vector}\n",
    "                    }\n",
    "                }\n",
    "             }\n",
    "    }\n",
    "\n",
    "    res= es.search(index='database',body=request)\n",
    "    l2 = []\n",
    "    for hit in res['hits']['hits']:\n",
    "        l2.append([hit['_score'] , hit['_id']])\n",
    "    \n",
    "    l1 = norm_list(l1)\n",
    "    l2 = norm_list(l2)\n",
    "    \n",
    "    # getting the weighted average score for the text search and semantics search\n",
    "    temp_doc = {}\n",
    "    for i in l1:\n",
    "        temp_doc[i[1]]  = i[0]*2\n",
    "    for i in l2:\n",
    "        temp_doc[i[1]] = temp_doc.get(i[1] , 0) + i[0]*5\n",
    "    \n",
    "    inverse_temp_doc = [(i[1] , i[0])  for i in temp_doc.items()]\n",
    "    inverse_temp_doc = sorted(inverse_temp_doc , reverse = True)\n",
    "    return inverse_temp_doc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Vector Encoder Results_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------Answer No:1--------------------------------------------------\n",
      "title :  why should leaf nodes in a red-black tree be black?\n",
      "\n",
      "\n",
      "question : from the property of red-black trees we know that: \n",
      "\n",
      "all leaves (nil) are black. (all leaves are same color as the root.)(comren et al \"introduction to algorithms\")\n",
      "\n",
      "\n",
      "but what is the reason that we should enforce them as black, even though they're nill's? \n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : take a uncolored leaf node, now you can color it as either red or black. if you colored it as red then you may have chance that your immediate ancestor is also red which is contradicting(according to basic principle). if you color it as black then no problem even though the immediate ancestor is red. and also no change in the number of black nodes from root to leaf paths(i.e every path get +1). this may be the possible reason behind that.\n",
      "\n",
      "subanswer 2 : it's simply a part of the definition of a red-black tree. it is also necessary to maintain one of the other rules associated with red-black trees: if a node is red, then both its children are black.\n",
      "\n",
      "--------------------------------------------------Answer No:2--------------------------------------------------\n",
      "title :  red black tree clarification\n",
      "\n",
      "\n",
      "question : i am quite new to red-black trees, and therefore i am having a bit of difficult time trying to understand them.\n",
      "one of the properties of the red-black tree is that every red vertex must have two black children, meaning one cannot have two consecutive red vertices.\n",
      "can someone explain to me why this is an essential property? what are the benefits of having such a property?\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : the properties of a red black tree allow insertion, deletion and search in $o(log(n))$. i guess you can find a prove online somewhere. \n",
      "when an element is inserted or deleted. a fix-up is done, it involves rotations in a tree, so the properties still hold. this ensures the tree is quitebalanced at all times and search is quite fast at all times.\n",
      "\n",
      "subanswer 2 : if you check the proof height-balancedness of red-black trees, you'll see that we essentially analyse the black-height $h_b$ of the tree which, by another important invariant, is the number of black nodes from the root to any leaf.\n",
      "the property you cite then gives us the right half of\n",
      "$\\qquad\\displaystyle h_b(t) \\leq h(t) \\leq 2h_b(t)$,\n",
      "which allows us to carry over bounds on black-height to usual height.\n",
      "\n",
      "--------------------------------------------------Answer No:3--------------------------------------------------\n",
      "title :  root color of a black red tree\n",
      "\n",
      "\n",
      "question : it is required that, in a black red tree, the color for the root is always black. however, wikipedia argues that this rule can be omitted as a red root can always be changed to black but not vice versa. i get the first half, that a red root can be changed to black at any time, but in what circumstance is it impossible to change a black node to red?\n",
      "for instance, consider the branch: black--red--black--red--black. we can always change it to red--black--black--red--black, since a black node does not need to have red children.\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : the root colour of a red-black tree carries no significance. in fact, you can save memory by not encoding it. didactically, it is meaningful to talk about a root's colour to illustrate what it means to be red or black, because it is a special case because it has no parent which is going to count it when it evaluates the sixth restriction in wikipedia's list (that the path from a particular node to a leaf should contain the same number of black nodes).\n",
      "as for your more general question about when changing a black node to a red one is allowed: a set of nodes can be repainted if afterwards, the black-height criterion is still satisfied. for example, if a row of the tree is saturated (if it is at depth $k$, there are $2^{k}$ nodes), then you can colour that row black. you may not colour only part of a (saturated or not) red row black. another example: in the tree $1:red \\rightarrow\\{ 2:black, 3:black\\rightarrow\\{4:red, 5:red\\}\\}$, you can flip the colours of $\\{3,4,5\\}$ and still have a legal rb tree. this is true generally for subtrees of even height and alternating colours. maybe you can think of more examples.\n",
      "\n",
      "--------------------------------------------------Answer No:4--------------------------------------------------\n",
      "title :  red-black tree. adding a red child to a red node with a black sibling\n",
      "\n",
      "\n",
      "question : according to my lecture notes, adding a red child to a red node with a black sibling in a red-black tree, is equivalent to changing a 3-node into a 4-node in a 2-3-4 tree. i've built several red-black trees with different values to try to get to this situation, but i never seem to get to the situation where i have a red node with a black sibling, and where the value to be inserted will be inserted below the red node. i'm starting to ask myself if this situation could ever happen in a red-black tree?\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : assume we have a black node $n$ with black child $l$ and red child $r$. thus we have a red and black sibling. recall that in a red-black tree all paths from root to leaf must have the same number of black nodes. the path $n-l$ contains two black nodes, the path $n-r$ just one. that means that both children of $r$ must be present, and must be black. so indeed, we can not add a new red child to $r$ because it already has black children. however, what can happen is that one of these black children turns red as consequence of a flag-flip. we then are in the situation you describe. \n",
      "\n",
      "--------------------------------------------------Answer No:5--------------------------------------------------\n",
      "title :  two red children in a red-black tree\n",
      "\n",
      "\n",
      "question : my data structures exam contains the following question:\n",
      "\n",
      "which of the statements below about red-black trees is true? (select one or more)\n",
      "\n",
      "every path from the root to a leaf has the same amount of red links.\n",
      "a node never has two red links to his childs.\n",
      "using a red-black tree, you can always draw the associated 2-3 tree.\n",
      "all leafs of a red-black tree are at the same height.\n",
      "\n",
      "\n",
      "the correct answer is: 2 and 3.\n",
      "i don't understand why a node can never have two red links to his child. on the image below (from wikipedia), i can see two red childs at node 25.\n",
      "could someone explain this to me?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : if 2 and 3 are both true, then the red-black trees you are sudying are not the standard ones, i.e., the ones from wikipedia.\n",
      "the red nodes are usually assumed to be \"satellites\" of the black node above. if there is at most one red node attached to a black one that means either one or to keays belong together (with altogether either two or three pointers to their children). that nicely corresponds to a 2-3 tree.\n",
      "the \"usual\" red-black trees can have two red children (but no red child to a red node) and correspond to 2-4 trees.\n",
      "\n",
      "--------------------------------------------------Answer No:6--------------------------------------------------\n",
      "title :  how can one search in o(log n) time in a red-black tree?\n",
      "\n",
      "\n",
      "question : how does the search operation for a red-black tree work and how does it take $o(\\log n)$ time, where $n$ is the number of items? i know a red-black tree takes $o(\\log n)$ recolorings and $o(1)$ rotations, but i was specifically interested in a good description of its search operation.\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : the search operation is the same for all binary search trees - recurse into the left or right branch depending on whether the element is smaller or larger than the current root. red-black trees are not special.\n",
      "the complexity of the search operation is equal to the height of the tree.\n",
      "different varieties of binary search trees differ in what guarantees on height of the tree they give, and in how exactly they maintain these guarantees. red-black trees and avl trees give you guaranteed o(log n) height, which is why search is o(log n).\n",
      "\n",
      "--------------------------------------------------Answer No:7--------------------------------------------------\n",
      "title :  red black tree and 2-3-4 tree isomorphism\n",
      "\n",
      "\n",
      "question : are all cases of addition and removal in 2-3-4 trees isomorphic to cases of addition and removal in red black trees?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "subanswer 1 : it depends what you mean by isomorphic. indeed a black node with its (zero, one or two) children corresponds to a 2-3-4 node (with 1,2,3 keys and 2,3,4 children). the basic operations on the two types of trees are really different but translate quite well. \n",
      "there is a single difference in symmetry: there is only one type of 3-node (2 keys, 3 children), whereas in a red-black tree the red child to the black node may be at the left or right side.\n",
      "\n",
      "--------------------------------------------------Answer No:8--------------------------------------------------\n",
      "title :  why are red-black trees so popular?\n",
      "\n",
      "\n",
      "question : it seems that everywhere i look, data structures are being implemented using red-black trees (std::set in c++, sorteddictionary in c#, etc.)\n",
      "having just covered (a,b), red-black & avl trees in my algorithms class, here's what i got out (also from asking around professors, looking through a few books and googling a bit):\n",
      "\n",
      "avl trees have smaller average depth than red-black trees, and thus searching for a value in avl tree is consistently faster.\n",
      "red-black trees make less structural changes to balance themselves than avl trees, which could make them potentially faster for insert/delete. i'm saying potentially, because this would depend on the cost of the structural change to the tree, as this will depend a lot on the runtime and implemntation (might also be completely different in a functional language when the tree is immutable?)\n",
      "\n",
      "there are many benchmarks online that compare avl and red-black trees, but what struck me is that my professor basically said, that usually you'd do one of two things:\n",
      "\n",
      "either you don't really care that much about performance, in which case the 10-20% difference of avl vs red-black in most cases won't matter at all.\n",
      "or you really care about performance, in which you case you'd ditch both avl and red-black trees, and go with b-trees, which can be tweaked to work much better (or (a,b)-trees, i'm gonna put all of those in one basket.)\n",
      "\n",
      "the reason for that is because a b-tree stores data more compactly in memory (one node contains many values) there will be much fewer cache misses. you could also tweak the implementation based on the use case, and make the order of the b-tree depend on the cpu cache size, etc.\n",
      "the problem is that i can't find almost any source that would analyze real life usage of different implementations of search trees on real modern hardware. i've looked through many books on algorithms and haven't found anything that would compare different tree variants together, other than showing that one has smaller average depth than the other one (which doesn't really say much of how the tree will behave in real programs.)\n",
      "that being said, is there a particular reason why red-black trees are being used everywhere, when based on what is said above, b-trees should be outperforming them? (as the only benchmark i could find also shows http://lh3lh3.users.sourceforge.net/udb.shtml, but it might just be a matter of the specific implementation). or is the reason why everyone uses red-black trees because they're rather easy to implement, or to put it in different words, hard to implement poorly?\n",
      "also, how does this change when one moves to the realm of functional languages? it seems that both clojure and scala use hash array mapped tries, where clojure uses a branching factor of 32.\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : red-black or avl trees have an advantage over b-trees and the like when the key is long or for some other reason moving a key is expensive.\n",
      "i created my own alternative to std::set within a major project, for a number of performance reasons.  i chose avl over red-black for performance reasons (but that small performance enhancement was not the justification for rolling my own instead of std::set).  the \"key\" being complicated and hard to move was a significant factor.  do (a,b) trees still make sense if you need another level of indirection in front of the keys?  avl and red-black trees can be restructured without moving keys, so they have that advantage when keys are expensive to move.\n",
      "\n",
      "subanswer 2 : to quote from the answer to “traversals from the root in avl trees and red black trees” question\n",
      "\n",
      "for some kinds of binary search trees, including red-black trees but\n",
      "  not avl trees, the \"fixes\" to the tree can fairly easily be predicted\n",
      "  on the way down and performed during a single top-down pass, making\n",
      "  the second pass unnecessary. such insertion algorithms are typically\n",
      "  implemented with a loop rather than recursion, and often run slightly\n",
      "  faster in practice than their two-pass counterparts.\n",
      "\n",
      "so a redblack tree insert can be implemented without recursion, on some cpus recursion is very expensive if you overrun the function call cache  (e.g sparc due to is use of register window) \n",
      "(i have seen software run over 10 times as fast on the sparc by removing one function call, that resulted in a often called code path being too deep for the register window.   as you don't know how deep the register window will be on your customer's system, and you don't know how far down the call stack you are in the \"hot code path\", not using recursion make like more predictable.)\n",
      "also not risking running out of stack is a benefit.\n",
      "\n",
      "subanswer 3 : well, this is not an authoritative answer, but whenever i have to code a balanced binary search tree, it's a red-black tree.  there are a few reasons for this:\n",
      "1) average insertion cost is constant for red-black trees (if you don't have to search), while it's logarithmic for avl trees.  furthermore, it involves at most one complicated restructuring.  it's still o(log n) in the worst case, but that's just simple recolorings.\n",
      "2) they require only 1 bit of extra information per node, and you can often find a way to get that for free.\n",
      "3) i don't have to do this very often, so every time i do it i have to figure it out how to do it all over again.  the simple rules and the correspondence with 2-4 trees makes it seem easy every time, even though the code turns out to be complicated every time.   i still hope that someday the code will turn out simple.\n",
      "4) the way the red-black tree splits the corresponding 2-4 tree node and inserts the middle key into the parent 2-4 node just by recoloring is super elegant.  i just love to do it. \n",
      "\n",
      "subanswer 4 : i've been researching this topic recently as well, so here are my findings, but keep in mind that i am not an expert in data structures!\n",
      "there are some cases where you can't use b-trees at all. \n",
      "one prominent case is std::map from c++ stl. the standard requires that insert does not invalidate existing iterators\n",
      "\n",
      "no iterators or references are invalidated.\n",
      "\n",
      "http://en.cppreference.com/w/cpp/container/map/insert\n",
      "this rules out b-tree as an implementation because insertion would move around existing elements.\n",
      "another similar use case are intrusive datastructures. that is, instead of storing your data inside the node of the tree, you store pointers to children/parents inside your structure:\n",
      "// non intrusive\n",
      "struct node<t> {\n",
      "    t value;\n",
      "    node<t> *left;\n",
      "    node<t> *right;\n",
      "};\n",
      "using walruslist = node<walrus>;\n",
      "\n",
      "// intrusive\n",
      "struct walrus {\n",
      "    // tree part\n",
      "    walrus *left;\n",
      "    walrus *right;\n",
      "\n",
      "    // object part\n",
      "    int age;\n",
      "    food[4] stomach;\n",
      "};\n",
      "\n",
      "you just can't make a b-tree intrusive, because it is not a pointer-only data structure. \n",
      "intrusive red-black trees are used, for example, in jemalloc to manage free blocks of memory. this is also a popular data structure in the linux kernel.\n",
      "i also believe that \"single pass tail recursive\" implementation is not the reason for red black tree popularity as a mutable data structure. \n",
      "first of all, stack depth is irrelevant here, because (given $\\log{n}$ height) you would run out of the main memory before you run out of stack space. jemalloc is happy with preallocating worst case depth on the stack.\n",
      "there are a number of flavors of red-black tree implementation. a famous one are left leaning red black trees by robert sedgewick (caution! there are other variants which also are named \"left leaning\", but use a different algorithm). this variant indeed allows to perform rotations on the way down the tree, but it lack the important property of $o(1)$  amortized number of fixups, and this makes it slower (as measured by the author of jemalloc). or, as opendatastrutures puts it\n",
      "\n",
      "andersson's variant of red-black trees, sedgewick's variant of red-black trees, and avl trees are all simpler to implement than the redblacktree structure defined here. unfortunately, none of them can guarantee that the amortized time spent rebalancing is $ o(1)$ per update. \n",
      "\n",
      "the variant described in opendatastructures uses parent pointers, a recursive down pass for insertion and an iterative loop up pass for fixups. the recursive calls are in a tail positions and compilers optimize this to a loop (i've checked this in rust). \n",
      "that is, you can get a constant memory loop implementation of a mutable search tree without any red-black magic  if you use parent pointers. this works for b-trees as well. you need magic for single pass tail recursive immutable variant, and it will break $o(1)$ fixup anyway.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------Answer No:9--------------------------------------------------\n",
      "title :  traversals from the root in avl trees and red black trees\n",
      "\n",
      "\n",
      "question : we all know that for insertion() operation in avl tree following can happen:\n",
      "we traverse down the tree from root to appropriate node and there insert the key and then for maintaining height balance we have to check heights of the ancestors of the newly inserted node and in doing so, we could end up traversing up to the root.\n",
      "i completely agree with this.\n",
      "but according to me the same can happen in red black tree because first we would traverse down the tree to appropriate node and then insert the key.then there is a possibility that a series of rotation and flip color operations could make us traverse the path up to the root.\n",
      "now my question is : why following statement is right?\n",
      "\n",
      "in avl tree insert() operation, we first traverse from root to newly inserted node and then from newly inserted node to root. while in red black tree insert(), we only traverse once from root to newly inserted node.\n",
      "\n",
      "it came as a question, which of the following statements is right about avl and red black trees and the option with given statement was marked correct in the answer key. i am trying to figure out mistake in my second observation?\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : for virtually all kinds of binary search trees, including avl trees and red-black trees, you can implement insertion in what is called a bottom-up fashion.  this involves two passes through the tree: the first pass starting at the root and moving down the tree to find the right place to do the insertion, and the second pass starting at the insertion point and moving upward toward the root fixing the tree as necessary.  frequently, these two passes are implemented as one recursive function, where the first pass is going down the recursion, and the second pass is coming back out of the recursion.\n",
      "for some kinds of binary search trees, including red-black trees but not avl trees, the \"fixes\" to the tree can fairly easily be predicted on the way down and performed during a single top-down pass, making the second pass unnecessary.  such insertion algorithms are typically implemented with a loop rather than recursion, and often run slightly faster in practice than their two-pass counterparts.\n",
      "note that, for trees like red-black trees, where you can implement insertion either way, the two different approaches (bottom-up/two-pass vs top-down/one-pass) do not necessarily yield exactly the same tree, but will yield trees that are equivalent.  for example, the exact pattern of red and black nodes may vary slightly, but will still obey all the expected invariants of a red-black tree. \n",
      "\n",
      "--------------------------------------------------Answer No:10--------------------------------------------------\n",
      "title :  insertions in red-black trees\n",
      "\n",
      "\n",
      "question : i studied methods for inserting new nodes into red-black trees for the first time this month.\n",
      "in doing so, i read a lot of pages on the internet and found that ( if i'm not mistaken ) there are many, many, many accepted algorithms for inserting nodes into red-black trees.\n",
      "furthermore, i noticed that it is possible to have two insertion algorithms that don't break red-black tree invariants, but also can start with the same initial tree, insert the same node, and end up with different resulting trees.\n",
      "i think.\n",
      "for example, take this website's algorithm for insertion:\n",
      "https://www.cs.usfca.edu/~galles/visualization/redblack.html\n",
      "and then there's this famous example from 'purely functional data structures' by chris okasaki:\n",
      "\n",
      "and then there's this algorithm from ohio state:\n",
      "https://www.pdf-archive.com/2017/03/28/08-red-black-tree/08-red-black-tree.pdf\n",
      "is it true that there are many red-black tree insertion algorithms that, given the same domain, will map the elements in that domain differently?\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : yes, a given set can be represented by multiple red-black trees, and this works incrementally, at least some of the time.  that is, there exists more than one valid red-black tree insertion algorithm, whose outputs are not always equal.\n",
      "the easiest way of seeing this is to focus on the correspondence between red-black trees and $(2, 4)$-b-trees.  a black node with its red children correspond to a b-tree node.\n",
      "in particular, if you have two sibling b-tree nodes with four elements in total, they can be distributed 1/3 or 2/2.  in red-black terms, if two black nodes are cousins, it's possible for each to have one red child, or for one of them to have two red children and the other to have none.  more than that, you can shuffle the elements around between the nodes locally to transform one such pattern into the other.\n",
      "as wikipedia says, \"the balancing of the tree is not perfect, but it is good enough to allow it to guarantee searching in o(log n) time\"; the imperfection of balancing gives room for multiple tree representations of the same set.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# getting the combined search results both semantic and the text based.\n",
    "answer_no = 1\n",
    "for i in search(\" what is red black trees ? \"):\n",
    "    print('-'*50 + \"Answer No:\" + str(answer_no) + '-'*50)\n",
    "    title = total_text_dictionary[i[1]][0]\n",
    "    question = total_text_dictionary[i[1]][1]\n",
    "    print(\"title : \" ,title )\n",
    "    print('\\n')\n",
    "    print(\"question :\" , question)\n",
    "    print('\\n')\n",
    "    sub_answer = 1\n",
    "    for i in total_text_dictionary[i[1]][2:]:\n",
    "        print(\"subanswer \" + str(sub_answer) +' : ' + i )\n",
    "        sub_answer+=1\n",
    "    answer_no+=1\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Vector Encoder Results_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------Answer No:1--------------------------------------------------\n",
      "title :  how hash-table and hash-map are different?\n",
      "\n",
      "\n",
      "question : in the context of cs, how the hash-table and hash-map are different? \n",
      "i was watching a part of \"algorithm with swift\" video in udacity, and i discovered the terms \"hash-table\" and \"hash-map\" are somewhat confusing.\n",
      "as far as i understand, \n",
      "\n",
      "hash table → stores keys only → swift set.\n",
      "hash map → stores key/value pairs → swift dictionary.\n",
      "\n",
      "but, wikipedia is talking hash-table is same thing with hash-map. here i could not find any help.\n",
      "is this formal or widely accepted cs term? am i understanding correctly? if i'm wrong, please correct me. thanks.\n",
      "\n",
      "i know industry uses their own terms that can be different, and i am asking about academia because i believe terms are more consistent in academia. if it's not, i just would abandon to learn academic terms.\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : if you ask me, you're correct and wikipedia is wrong, as the complaints on the article's talk page (some 11 years ago!) clearly explain, but it was never fixed (or it was fixed and reverted).\n",
      "a hash table stores items; these items can be keys (in which case it implements a set), or key-value pairs (in which case it implements a map, i.e. a hash map), or perhaps something else, e.g. triples; the wikipedia article describes only the key-value case, while i was only taught the key-only case in class.\n",
      "some people do use hash table to mean hash map, so wikipedia successfully describes a particular usage of the term; it should also describe the other cases. (it does describe how a hash map can be used to implement a set and other data structures, but that's not the same thing.)\n",
      "in it, most terms mean different things to different people, and most people using the term in one sense aren't aware that other people use it in another sense; hash table is no exception.\n",
      "\n",
      "--------------------------------------------------Answer No:2--------------------------------------------------\n",
      "title :  why does hashmap allow only one null key?\n",
      "\n",
      "\n",
      "question : a hashmap allows only one null key. is it because it allows only unique keys?  or is there another reason?\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : why is it confusing? the javadoc for hashmap.put clearly states:\n",
      "\n",
      "associates the specified value with the specified key in this map. if the map previously contained a mapping for the key, the old value is replaced.\n",
      "\n",
      "it clearly states what happens when you do a put with a key which was already in the map. the specific case of key == null behaves in the same way: you can't have two different mappings for the null key (just like you can't for any other key). it's not a special case, for the context of your question.\n",
      "\n",
      "--------------------------------------------------Answer No:3--------------------------------------------------\n",
      "title :  why isn't an edge-map graph implementation used in practice?\n",
      "\n",
      "\n",
      "question : wikipedia states that three different graph implementations that are used in practice:\n",
      "\n",
      "adjacency lists\n",
      "adjacency matrix\n",
      "incidence matrix\n",
      "\n",
      "while i was learning about these structures, another implementation occurred to me that seems to have better asymptotic properties than wikipedia's. my idea is to create a hash map where the keys are (vertex, vertex) pairs and the values are the cost of their edge.\n",
      "given that inserting into and querying from a hash map is $o(1)$, i believe the time complexity would be the following:\n",
      "\n",
      "store graph: $o(e)$\n",
      "add vertex: $o(1)$\n",
      "add edge: $o(1)$\n",
      "remove vertex: $o(v)$\n",
      "remove edge: $o(1)$\n",
      "query cost between vertices: $o(1)$\n",
      "\n",
      "since this implementation has strictly better time and space complexity then all three options listed, i'm confused as to why this option isn't.\n",
      "why isn't this implementation used in practice?\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : assume we are dealing with the representation of a weighted graph. i will use python as the programming language to illustrate the points, which will remain true largely if another programming language is used.\n",
      "let us call the graph representation raised in the question \"hashmap from edges to their weights\" or \"edge-weight hashmap\". i would agree that an edge-weight hashmap is seldom used to represent a weighted graph. \n",
      "one overwhelming reason is that compared to edge-weigh hashmap, it is usually preferred to use the following popular variation of adjacency list, which i will call \"adjacent hashmaps\" or \"nested hashmaps\". the entire graph is represented by a big hashmap $g$, a.k.a. the outer hashmap, which is a collection of $(v, g[v])$ pairs, where $v$ is a vertex and $g[v]$ is a smaller hashmap, a.k.a. the inner hashmap. $g[v]$ is a collection of of $(u, w)$ pairs, where each vertex $u$ is a vertex that is adjacent to $v$ and $w$ is the weight of edge $(v,u)$.\n",
      "an example\n",
      " \n",
      "$\\begin{array}{c|c}\n",
      " \\text{nested hashmap} & \\text{edge-weight hashmap} \\\\\\hline\n",
      "  \\begin{array}{l@{}l@{}l@{}lll}\n",
      "\\{\\\\\n",
      "\\quad1: &\\{2:2,&4:5\\},\\\\\n",
      "\\quad2: &\\{1:2, &3:14, &4:5, &5:4\\},\\\\\n",
      "\\quad3: &\\{2:14,&5:34\\},\\\\\n",
      "\\quad 4: &\\{1:5, &2:5, &5:58\\},\\\\\n",
      "\\quad 5: &\\{2:4, &3:34, &4:58\\}\\\\\n",
      "\\}\\end{array}                & \n",
      "\\begin{array}{lllll}\n",
      "\\{\\\\\n",
      "\\quad(1,2):2,           &(1,4):5,\\\\\n",
      "\\quad(2,1):2, &(2,3):14,&(2,4):5,&(2,5):5,\\\\\n",
      "\\quad(3,2):14,&(3,5):34,\\\\\n",
      "\\quad(4,1):5, &(4,2):5, &(4,5):58,\\\\\n",
      "\\quad(5,2):4, &(5,3):34,&(5,4):58\\\\\n",
      "\\}\\end{array} \\\\\n",
      "\\end{array}$\n",
      "the alignment of data entries above is meant for easy reading of python code. by the general nature of hashmap, the actual storage locations of the entries in a hashmap are sort of unpredictable.\n",
      "comparison of complexity between nested hashmaps and edge-weight hashmap \n",
      "$\\begin{array}{|l|c|c|}\\hline\n",
      "&\\text{nested hashmap} & \\text{edge-weight hashmap}\\\\\\hline \n",
      "\\text{store graph} &o(|e|) &o(|e|)\\\\\\hline\n",
      "\\text{add vertex} &o(1) &o(1)\\\\\\hline\n",
      "\\text{add edge} &o(1) &o(1)\\\\\\hline\n",
      "\\text{remove vertex} &o(|v|)&o(|v|)\\\\\\hline\n",
      "\\text{remove edge} &o(1) &o(1)\\\\\\hline\n",
      "\\text{check if two vertices are adjacent} &o(1) &o(1)\\\\\\hline\n",
      "\\text{list neighborhood of a vertex }&o(|v|) &?\\ o(|e| )\\ ?\\\\\\hline\n",
      "\\end{array}$\n",
      "the entry \"$?\\ o(|e| )\\ ?$\" entry on the column of \"edge-weight hashmap\" means that it is not clear how to list neighborhood of a given vertex $v$ efficiently. $o(|e|)$ refers to the time-complexity of the natural way, which goes over all the edges, keeping only the edges that contain $v$.\n",
      "so both implementations have the same asymptotic time-complexity and space-complexity for all operations, except for listing the neighborhood of a vertex, arguably the most popular iteration on a graph, for which nested hashmaps are significantly faster. in practice, nested hashmaps should also exhibit better cache-friendliness. \n",
      "comparison of programming friendliness\n",
      "here are the code that does the basic iterations over a graph represented in variable $g$ using nested hashmap or edge-weight hashmap.\n",
      "$\\begin{array}{|l|l|c|}\\hline\n",
      "&\\text{nested hashmap} & \\text{edge-weight hashmap}\\\\\\hline \n",
      "\\text{iterate over all vertices} &\\text{for v in g:} &???\\\\\\hline\n",
      "\\text{iterate over the neighborhood of vertex u} &\\text{for v in g[u]:} &???\\\\\\hline\n",
      "\\text{iterate over all edges} &\\begin{array}{c}\\text{for u in g:}\\quad\\quad\\\\\\text{ for v in g[u]:}\\end{array} &\\text{for e in g:}\\\\\\hline\n",
      "\\end{array}$\n",
      "the \"???\" entries on the column of \"edge-weight hashmap\" means that it seems rather clumsy to write that piece of code in python or other programming languages, assuming their generally-available implementations of hashmap.\n",
      "nested hashmaps are far more programmer-friendly than edge-weight hashmap.  \n",
      "summary\n",
      "although the time-complexity of the most basic operations using edge-weight hashmap are very good, it does not support the basic iterations well. it should be replaced by nested hashmaps in general.\n",
      "exercises\n",
      "exercise 1. verify that this answer is applicable for weighted directed graph after slight adaptation. verify that this answer is applicable for (unweighted) directed or undirected graph as well. \n",
      "exercise 2. compare edge-weight hashmap with adjacent-weight list in detail. an adjacent-weight list for the graph above in python can be $g=[[], [(2,2), (4,2)],$ $[(1,2), (3,14), (4,5), (5,5)],$ $[(2,14), (5, 34)],$ $[(1,5), (2,5), (5,58)],$ $[(2,4), (3,34), (4,58)]]$, where $g[v]$ is a list of $(u,w)$ pairs for vertex $v=1,2,3,4,5$ (g[0] is ignored since 0 is not a vertex), where $w$ is the weight of edge $(v,u)$. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "subanswer 2 : there's at least two points that should be raised here: \n",
      "\n",
      "insert and query for a hash table are not in general constant time operations in the worst case. \n",
      "there is typically no implementation that would be suitable for every possible case (i.e., different algorithms might benefit from different implementations of the graph). as an example, it doesn't seem clear how you would efficiently iterate over the neighbors of a vertex which several graph algorithms need.\n",
      "\n",
      "\n",
      "--------------------------------------------------Answer No:4--------------------------------------------------\n",
      "title :  can you insert into sorted list with time o(1)?\n",
      "\n",
      "\n",
      "question : wondering if this was possible. if i have a sorted list, can i find the right spot for an integer and insert it, all in o(1) time? the only way i can think to do this is via having a massive hashmap with one slot for each possible integer. 2 billion different integers * 4 bytes per integer = 8 gigabytes....but it'd technically work. there has to be a better way to do this though, right?\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : one thing before i explain: hashmap doesn't use an array that big, it uses chaining, which is another concept you'll have to look up. and if you're talking about creating an array size 2 billion, that still won't work because you still have to scan the 2 billion entries in the array. ok, technically that's o(1), but only because o(2 billion) is counted as o(1).\n",
      "i actually wondered about this for a long time. if you think about it, there is no possible way even with the hashmap. before i get into why hashmap doesn't work, if you don't use a hashmap, you'll have to scan the whole size that you have to insert. now to the hashmap part, after inserting you're number, you'll have to update every entry after that. and if you don't, you'll get an o(1) insertion once, but after that you'll get wrong insertions.\n",
      "\n",
      "subanswer 2 : sounds like you want a solution for bounded integers, 32-bit for example. if so, any sorted dictionary whose complexity depends on the key length only will do what you want. two examples are binary trie and van emde boas tree.\n",
      "\n",
      "--------------------------------------------------Answer No:5--------------------------------------------------\n",
      "title :  java.util.hashmap lock on actual hashmap object compare to lock on object that encapsulate the hashmap\n",
      "\n",
      "\n",
      "question : the below javadoc is an snippet of hashmap documentation. why authors would emphasize on putting a lock on the object that encapsulate a hashmap? lock on the actual hashmap object makes for sense. \n",
      "\n",
      "note that this implementation is not synchronized. if multiple threads access a hash map concurrently, and at least one of the threads modifies the map structurally, it must be synchronized externally. (a structural modification is any operation that adds or deletes one or more mappings; merely changing the value associated with a key that an instance already contains is not a structural modification.) this is typically accomplished by synchronizing on some object that naturally encapsulates the map. if no such object exists, the map should be \"wrapped\" using the collections.synchronizedmap method...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : encapsulation is necessary here in order to restrict direct access of client code to methods of hashmap.\n",
      "as for recommendation on what object to use as a lock, it serves a purpose to allow client code to iterate over the map in a thread safe way.\n",
      "if you intend your map to be synchronized but lock on actual hashmap object, without hiding (encapsulating) it, then any code having access to that object would be able to invoke its unsynchronized methods and break synchronization. purpose of encapsulation in this case is stated further in javadocs you refer: \"to prevent accidental unsynchronized access to the map\".\n",
      "documentation also refers to collections.synchronizedmap as an example on how one is expected to synchronize:\n",
      "\n",
      "returns a synchronized (thread-safe) map backed by the specified map. in order to guarantee serial access, it is critical that all access to the backing map is accomplished through the returned map...\n",
      "\n",
      "you see, synchronizedmap documentation reiterates the importance (\"it is critical\") for the client code not accessing \"backing map\" directly.\n",
      "this documentation also further provides the example explaining why it is recommended to synchronize on the enclosing object:\n",
      "\n",
      "it is imperative that the user manually synchronize on the returned map when iterating over any of its collection views:\n",
      "  map m = collections.synchronizedmap(new hashmap());\n",
      "      ...\n",
      "  set s = m.keyset();  // needn't be in synchronized block\n",
      "      ...\n",
      "  synchronized (m) {  // synchronizing on m, not s!\n",
      "      iterator i = s.iterator(); // must be in synchronized block\n",
      "      while (i.hasnext())\n",
      "          foo(i.next());\n",
      "  }\n",
      "\n",
      "failure to follow this advice may result in non-deterministic behavior. \n",
      "\n",
      "you see, in the above code example, if client code would not have access to \"known by convention\" lock object, it would be impossible to properly synchronize: some other code could have used other lock to wrap the iteration which would lead to unsynchronized access.\n",
      "\n",
      "subanswer 2 : i understand it as saying that an \"easy\" way is to use the synchronized wrappers or make the class holding the map synchronized (i.e. using synchronized methods, which is what the wrappers does essentially).\n",
      "but there are other ways, such as synchronising on the map itself if it is private and final, using a separate lock object or using a concurrentmap. i wouldn't overthink what is said here and simply apply usual concurrency patterns.\n",
      "\n",
      "--------------------------------------------------Answer No:6--------------------------------------------------\n",
      "title :  does making the keys of a hashtable the same length make the hashtable any better?\n",
      "\n",
      "\n",
      "question : the question popped up in my head. the hash function used is murmur3.\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : it makes the hash table unusable if i can’t have x and yz and abc as keys. \n",
      "\n",
      "--------------------------------------------------Answer No:7--------------------------------------------------\n",
      "title :  what is the difference between a hash and a dictionary?\n",
      "\n",
      "\n",
      "question : what is the difference between hash and dictionary? \n",
      "coming from a scripting background, i feel that they are similar, but i wanted to find out the exact differences. googling did not help me much. \n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : \"dictionary\" is the name of the concept. a hashtable is a possible implementation.\n",
      "\n",
      "subanswer 2 : a dictionary is the collective term given for any data structure implementation used for fast lookups/insertions. this can be achieved/implemented using a variety of data structures like hash table, skip lists, rb tree etc. a hash table is a specific data structure useful for many purposes including implementing a dictionary.\n",
      "\n",
      "subanswer 3 : a dictionary uses a key to reference the value directly inside of an associative array.\n",
      "i.e (key => value)\n",
      "a hash is more often described as a hash table which uses a hash function to calculate the position in memory (or more easily an array) where the value will be. the hash will take the key as input and give a value as output. then plug that value into the memory or array index.\n",
      "i.e key => hash function => value\n",
      "i guess one is direct while the other isn't. hash functions may not be perfect either and may sometimes provide an index referencing the wrong value. but that can be corrected.\n",
      "best place to look: wikipedia (associative array and hash table)\n",
      "\n",
      "subanswer 4 : hash is an extremely poorly named data structure where the programmer has confused the interface with implementation (and was too lazy to write the full name, i.e. hashtable instead resorting to an abbreviation, hash).\n",
      "dictionary is the “correct” name of the interface (= the adt), i.e. an associative container that maps (usually unique) keys to (not necessarily unique) values.\n",
      "a hash table is one possible implementation of such a dictionary that provides quite good access characteristics (in terms of runtime) and is therefore often the default implementation.\n",
      "such an implementation has two important properties:\n",
      "\n",
      "the keys have to be hashable and equality comparable.\n",
      "the entries appear in no particular order in the dictionary.\n",
      "\n",
      "(for a key to be hashable means that we can compute a numeric value from a key which is subsequently used as an index in an array.)\n",
      "there exist alternative implementations of the dictionary data structure that impose an ordering on the keys – this is often called a sorted dictionary (and is usually implemented in terms of a search tree, though other efficient implementations exist).\n",
      "\n",
      "to summarize: a dictionary is an adt that maps keys to values. there are several possible implementations of this adt, of which the hash table is one. hash is a misnomer but in context it’s equivalent to a dictionary that is implemented in terms of a hash table.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------Answer No:8--------------------------------------------------\n",
      "title :  why define a java object using interface (e.g. map) rather than implementation (hashmap)\n",
      "\n",
      "\n",
      "question : in most java code, i see people declare java objects like this:\n",
      "map<string, string> hashmap = new hashmap<>();\n",
      "list<string> list = new arraylist<>();\n",
      "\n",
      "instead of:\n",
      "hashmap<string, string> hashmap = new hashmap<>();\n",
      "arraylist<string> list = new arraylist<>();\n",
      "\n",
      "why is there a preference to define the java object using the interface rather than the implementation that is actually going to be used?\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : having the variable constrained to an interface ensures none of the usages of that variable will be using hashmap specific functionality that may not exist on the interface, so the instance may be changed without concern later to a different implementation so long as the new instance also implements the interface.\n",
      "for this reason, anytime you want to use an objects interface, it is always good practice to declare your variables as the interface and not the particular implementation, this goes for all types of objects you may use which have an interface. the reason you see it often is many people have built this in as a habit.\n",
      "that said, it's not harmful to skip out of using interfaces sometimes, and most of us sloppily don't always follow this rule, with no real harm. it's just a good practice to stick to when you have any feeling the code may be changed and need maintenance/growth in the future. it's less of a concern when you're hacking on code you don't suspect will have a long life or has much importance. also breaking this rule usually has a small consequence  that changing the implementation to another one may require a bit of refactoring, so if you don't always follow it you won't hurt yourself a lot, though there's no real harm in following it either.\n",
      "\n",
      "subanswer 2 : the reason is that the implementation of these interfaces is usually not relevant when handling them, therefore if you oblige the caller to pass a hashmap to a method, then you're essentially obliging which implementation to use.  so as a general rule, you're supposed to handle its interface rather than the actual implementation and avoid the pain and suffering which might result in having to change all method signatures using hashmap when you decide you need to use linkedhashmap instead.\n",
      "it should be said that there are exceptions to this when implementation is relevant.  if you need a map when order is important, then you can require a treemap or a linkedhashmap to be passed, or better still sortedmap which doesn't specify a specific implementation. this obliges the caller to necessarily pass a certain type of implementation of map and strongly hints that order is important.  that said, could you override sortedmap and pass an unsorted one?  yes, of course, however expect bad things to happen as a result.\n",
      "however best practice still dictates that if it isn't important, you shouldn't use specific implementations.  this is true in general.  if you're dealing with dog and cat which derive from animal, in order to make best use of inheritance, you should generally avoid having methods specific to dog or cat.  rather all methods in dog or cat should override methods in animal and it will save you trouble in the long run.\n",
      "\n",
      "subanswer 3 : it's to follow the interface segregation principle (the 'i' in solid).  it prevents code that uses those objects from depending on methods of those objects it doesn't need, which makes the code less coupled, and therefore easier to change.\n",
      "for example, if you find out later you really need a linkedhashmap, you can safely make that change without affecting any other code.\n",
      "however, there's a trade off, because you're artificially limiting the code that can take your object as a parameter.  say there's a function somewhere that requires a hashmap for some reason.  if you return a map, you can't pass your object into that function.  you have to balance the likelihood of sometime in the future needing the extra functionality that's in the more concrete class  with the desire to limit coupling and keep your public interface as small as possible.\n",
      "\n",
      "subanswer 4 : in layman's words:\n",
      "the same reason electric apliances makers built their products with electrical plugs instead of simply peeled out cables, and houses come with wall sockets instead of peel out cables sticking out of the wall.\n",
      "by using standard plugs instead, they allow to plug the same apliances in any compatible plug around the house.\n",
      "from the point of view of the wall socket, it doesn't matter whether you plug a tv set or a stereo.\n",
      "that makes both the appliance and the socket more useful.\n",
      "take for example a method that accepts a map as an argument.\n",
      "the method willl work regardless of you passing a hashmap or a linkedhashmap to it, as long it's a subclass of map.\n",
      "that's liskov substitution principle.\n",
      "in the sample code you gave, it means you can later, for some reason, change the concrete implementation of hash and you will not need to change the rest of the code.\n",
      "the problem with software is that, since it's relatively easy to change things later with no waste of bricks or mortar, people assume that kind of fore-thought is not worth the while. but reality has showed us that software maintenance is very expensive.\n",
      "\n",
      "--------------------------------------------------Answer No:9--------------------------------------------------\n",
      "title :  history/etymology- map/[hash]map vs map()\n",
      "\n",
      "\n",
      "question : forgive me/delete this question if it doesn't qualify as computer science:\n",
      "i've always wondered about the relationship between map the data structure and map() the function. i know they are two different things. why share the name?\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : well, i am only a beginning msc student in computerscience but if if followed the classes correctly the purpose of a hash is to create some memory space, let say this memory space is 10 adresses big. with a hashmap, every value you put in the hashmap gets coupled with a key. that key will first be mapped by a hashfunction to produce a unique number. that number is within the range of possible adresses in the vector. $ f: a \\mapsto b $ with a the collection of possible keys and b a collection of possible adresses. mathematically speaking this is a mapping. the value gets then saved to that adress. now it is possible that you want to save more values than the vector allows or the hashfuntion is not completely one on one (that is every y has a unique x value it corresponds to) in that case you wil need to make the vector longer and remap every value within the vector or you reshash the value from the hashfunction with that same same value it has returned (usualy slightly edited to avoid all values being at the same place in the vector) as the parameter to find a new adress that wasn't used before. there are a number of other techniques involved and other methods but that is beside the point.\n",
      "long story short. this mapping of key values is, i believe, the reason it is called a hashmap.\n",
      "\n",
      "--------------------------------------------------Answer No:10--------------------------------------------------\n",
      "title :  mvc design, singleton in model with initialization\n",
      "\n",
      "\n",
      "question : i've recently learned of mvc (model view controller) and am trying to refactor an existing program.  i am in a situation where i'd like to have exactly one object of a particular class so it seemed evident that i should use a singleton.  this singleton will be used to keep a hashmap of certain things.  however this hashmap will have to be initialized when the singleton is created by reading nodes from a xml file and storing them as class objects.\n",
      "now my dilemma is:\n",
      "\n",
      "if i initialize the xml attributes (reading and converting to class objects), i'm effectively doing things in the model class that the controller should be doing, which is definitely not good. \n",
      "if i put the initialization method in a controller class, i would have to refer to a controller class from a model class, which does not conform to the mvc design.\n",
      "if i put the whole singleton in controller, then i'd have to look for the hashmap in the controller package, which defeats the purpose of having model classes.\n",
      "i can't pass a premade hashmap to the singleton as a parameter neither, because the constructor is private..  well, i technically could, by giving it to the getinstance() method as a parameter, but it feels like a dirty way of fixing, since i now either pass null every time, or make another getinstance() method that doesn't accept a  parameter.\n",
      "\n",
      "right now, my code is looking like this:\n",
      "public class categorycatalog{\n",
      "\n",
      "    private static categorycatalog categorycatalog;\n",
      "    private hashmap<caroptioncategory, set<icaroption>> categoryoptionsmap;\n",
      "\n",
      "    private categorycatalog(){\n",
      "        categoryoptionsmap = new hashmap<caroptioncategory, set<icaroption>>();\n",
      "        initialize();\n",
      "    }\n",
      "\n",
      "    public static categorycatalog getinstance(){\n",
      "        if(categorycatalog == null){\n",
      "            categorycatalog = new categorycatalog();\n",
      "        }\n",
      "        return categorycatalog;\n",
      "    }\n",
      "\n",
      "    private void initialize(){\n",
      "        // todo: xml\n",
      "    }\n",
      "}\n",
      "\n",
      "am i overlooking something or should i use a different approach?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "subanswer 1 : you have to use the right tool for the right problem. mvc is used to separate the representation logic from routing request logic (controller) and business logic (the model).\n",
      "for creating objects you should use creational patterns. now, in my opinion,\n",
      "\n",
      "if i initialize the xml attributes (reading and converting to class\n",
      "  objects), i'm effectively doing things in the model class that the\n",
      "  controller should be doing, which is definitely not good.\n",
      "\n",
      "it's good if the classes are used by the model.\n",
      "\n",
      "if i put the initialization method in a controller class, i would have\n",
      "  to refer to a controller class from a model class, which does not\n",
      "  conform to the mvc design.\n",
      "\n",
      "yep, don't do this because a low lever layer should not depend of a higher layer.\n",
      "\n",
      "if i put the whole singleton in controller, then i'd have to look for\n",
      "  the hashmap in the controller package, which defeats the purpose of\n",
      "  having model classes.\n",
      "\n",
      "this singleton is not a controller so don't do that too.\n",
      "\n",
      "i can't pass a premade hashmap to the singleton as a parameter\n",
      "  neither, because the constructor is private.. well, i technically\n",
      "  could, by giving it to the getinstance() method as a parameter, but it\n",
      "  feels like a dirty way of fixing, since i now either pass null every\n",
      "  time, or make another getinstance() method that doesn't accept a\n",
      "  parameter.\n",
      "\n",
      "yep, you will break encapsulation here because the hash map is an invariant of your class and if you accept a hash map it means that the invariant can be overwritten, maybe accidentally.\n",
      "in my opinion this singleton is some kind of factory that provides classes, if the classes are used by the model, then put this singleton in your model package. also take a look at spring, it will do this for you in a nice way.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# getting the combined search results both semantic and the text based.\n",
    "answer_no = 1\n",
    "for i in search(\" what is hashmap ? \"):\n",
    "    print('-'*50 + \"Answer No:\" + str(answer_no) + '-'*50)\n",
    "    title = total_text_dictionary[i[1]][0]\n",
    "    question = total_text_dictionary[i[1]][1]\n",
    "    print(\"title : \" ,title )\n",
    "    print('\\n')\n",
    "    print(\"question :\" , question)\n",
    "    print('\\n')\n",
    "    sub_answer = 1\n",
    "    for i in total_text_dictionary[i[1]][2:]:\n",
    "        print(\"subanswer \" + str(sub_answer) +' : ' + i )\n",
    "        sub_answer+=1\n",
    "    answer_no+=1\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Vector Encoder Results_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------Answer No:1--------------------------------------------------\n",
      "title :  finding an element in a infinite unsorted doubly linked list\n",
      "\n",
      "\n",
      "question : is there any way to find an element in an unsorted doubly linked list given an element and pointer from which we can navigate? (we can't use head/tail pointers since the list is infinite)\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : infinite/unbounded in both directions?\n",
      "zig-zag.\n",
      "\n",
      "--------------------------------------------------Answer No:2--------------------------------------------------\n",
      "title :  a question about linked list\n",
      "\n",
      "\n",
      "question : i would like to check the answer of this exercise:\n",
      "a circular doubled linked list with n elements has pointers that cost k bytes each of space in memory. how many bytes do the pointers of this list cost in total?\n",
      "researching about circular linked lists, i can assume that each node has 2 pointers. so am i right to say that the answer is 2(n)k bytes?\n",
      "thanks.\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : the list takes $2*n*k$ bytes in total. a circular linked list is just a simple linked list with its last node's next pointer pointing back towards head. so, no extra pointer is required to make it circular. hence, the total space is $2*n*k$.\n",
      "\n",
      "--------------------------------------------------Answer No:3--------------------------------------------------\n",
      "title :  what's the advantage of two pointers linked list implementation of queue versus one pointer circular list\n",
      "\n",
      "\n",
      "question : princeton algorithms course shows the implementation of queue using linked list and two pointers - head and tail. i've implemented the same functionality as a circular linked list using only one pointer tail. i'm wondering what's the advantage of two pointers versus one in a circular list. it takes more space as i understand so why did they choose this implementation?\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : one possible advantage is that it is a little easier to understand how the push and pop operations work with a doubly-linked list.  the use of a singly-linked circular list is not that much harder to understand, but it is a trick, and at this stage where it's the first time you're seeing anything of the sort, any extra complication can be extra confusing.\n",
      "\n",
      "subanswer 2 : if you're not using a circular list, then you must have a pointer to head and tail to achieve $o(1)$ enqueue and dequeue. furthermore, if it is not a circular list and not a doubly-linked list, then without a pointer to head, we can't enqueue!\n",
      "some picture might help a little too.\n",
      "\n",
      "single linked list with only tail pointer:\n",
      "\n",
      "there's no way to get back to the head to enqueue! we would have to remedy this with a pointer to the head.\n",
      "doubly linked list with only tail pointer:\n",
      "\n",
      "we can get back to the head, but at an $o(n)$ cost, we might as well just add another pointer to head for convenience.\n",
      "single circular linked list with only tail pointer:\n",
      "\n",
      "we can get back to the head in $o(1)$! this is a good shortcut. in circular linked lists this node can sometimes implemented as a sentinel node which does not contain any information but works as a separator between the head and tail of the queue.\n",
      "\n",
      "in terms of additional space, adding tail or head or both is almost negligible. the nodes will be taking up memory no matter what, it's just whether or not you use a variable to reference them. using a circular linked list kind of acts like a head pointer if you think about it. tail.next would be a synonym for head, so it's not really saving space, nor is it really costing much space.\n",
      "\n",
      "--------------------------------------------------Answer No:4--------------------------------------------------\n",
      "title :  using singly linked list instead of a doubly linked list?\n",
      "\n",
      "\n",
      "question : are there advantages of implementing a singly instead of a doubly linked list other than space?\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : other than saving space, the first advantage i can see for singly\n",
      "linked lists over doubly linked lists is to avoid having to update two\n",
      "links instead of one when you modify the list, when adding an element\n",
      "for example.\n",
      "of course, one might say that you can always ignore the second link,\n",
      "but in that case, it is no longer doubly linked, but only an unused\n",
      "field.\n",
      "what might also be seen as an advantage is that singly linked list are\n",
      "necessarily consistent, though possibly wrong when there are bugs in\n",
      "the program.  doubly linked lists can end-up having inconsistent links\n",
      "forward and backward. but it is debatable which of the two cases, if\n",
      "any, is an advantage.\n",
      "update:\n",
      "i had tried to see some impact on garbage collection, but found\n",
      "none. actually, there is one when storage reclamation is done by\n",
      "reference counting, as reference counting is defeated by loops, and\n",
      "doubly linked lists contain loops. singly linked list escape the\n",
      "problem. of course, there are ways around it for doubly linked lists,\n",
      "such as the use of weak pointers, or programmable reference counting\n",
      "as part of data abstraction.\n",
      "\n",
      "subanswer 2 : yes. singly linked lists are easier to work with in highly concurrent situations, because there's less data to keep consistent.\n",
      "for example, suppose you want to append a lot of items to a linked list in a wait-free way. it's okay if consuming the items is not wait free, but producers absolutely must not block no matter what the other threads are doing.\n",
      "with a singly linked list you can just do:\n",
      "var newnode = new node(somevalue);\n",
      "var prevnode = interlocked.exchange(ref _insertionnode, newnode);\n",
      "prevnode.next = newnode; //note: next is volatile; this is a write-release\n",
      "\n",
      "easy! guaranteed progress for every producer. produced  nodes may not be immediately visible from the head of the list (a previous producer may have yet to update the next pointer of the node it got), but they eventually will be.\n",
      "with a doubly-linked list, you need cas loops and other try-retry-retry-fix-up sorts of constructs. it's a lot easier to make a mistake, so i won't try to just zip off an example.\n",
      "\n",
      "--------------------------------------------------Answer No:5--------------------------------------------------\n",
      "title :  does the head(start) pointer of doubly linked list points previously to the tail(last) node\n",
      "\n",
      "\n",
      "question : i have one question in my mind that in case of circular doubly linked list the head pointer of the doubly linked list also logically point to the next pointer of the tail node of the linked list and tail's next pointer also point to the previous pointer of head.\n",
      "please answer me this question i am a bit confused.\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : assume you have a circular doubly linked list with three nodes at position 1, 2 and 3:\n",
      "[1] next->2 prev->3\n",
      "[2] next->3 prev->1\n",
      "[3] next->1 prev->2\n",
      "\n",
      "in some sense there is no \"head\" and \"tail\" in a circular doubly linked list. though you will have a pointer outside as an entry point to access the list like head->1, which would be identical to 3:next->1.\n",
      "so the heads prev points to the \"tail\"\n",
      "the tails next points to the \"head\"\n",
      "\n",
      "subanswer 2 : it depends.\n",
      "is it a circular or linear list?\n",
      "if it's a circular list then there is no \"head\" or \"tail\" as each element's next and prev pointers will be set. you can start traversing the list anywhere and have to remember where you started so you know when to stop.\n",
      "if it's a linear list then the prev pointer of the head element will be null and the next pointer of the tail element will be null. you use this information to know when to stop.\n",
      "\n",
      "subanswer 3 : i've used a circular doubly linked list like this:\n",
      "typedef struct list {\n",
      "  struct list *next;\n",
      "  struct list *prev;\n",
      "  void *data;\n",
      "} list;\n",
      "\n",
      "i decided to define the head of a list as one that has data == null. so an empty list is one where next and prev point to itself and data == null. you can then insert before or after the head at will. you can iterate the list by starting at head->next and going till you hit head again.\n",
      "and here is the fun part: you can have multiple heads. nothing prevents you from inserting a second list with data == null. now there are two ways to iterate over the list: you can iterate till you hit the next head (data == null) or skip over heads and keep going till you hit the original head again.\n",
      "\n",
      "--------------------------------------------------Answer No:6--------------------------------------------------\n",
      "title :  building heaps and heapsort using linked list\n",
      "\n",
      "\n",
      "question : i know that linked list is not a appropriate data structure for building heaps but i am interested in knowing the time complexity of building heaps and heapsort using linked list.\n",
      "one of the answers here (https://stackoverflow.com/a/14584517/5841727) says that heap sort can be done in o(nlogn) using linked list which is same as with arrays.\n",
      "for building a heap, i think that heapify operation would cost  o(n) time in linked list and we would need (n/2) heapify operations leading to time complexity of o(n^2). is it correct?\n",
      "also, can someone please tell how to achieve o(nlogn) complexity (for heap sort ) using linked list ?\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : doubly linked list can be sorted by heapsort with o(nlogn) time, o(1) space complexity, but not singly linked-list.\n",
      "merge sort can apply to singly linked list with o(nlogn) time, o(n) space complexity.\n",
      "\n",
      "--------------------------------------------------Answer No:7--------------------------------------------------\n",
      "title :  linked list with merge sort\n",
      "\n",
      "\n",
      "question : is merge sort the best sorting technique to sort a linked list? also, which sorting technique is worst for a linked list?\n",
      "\n",
      "merge sort uses a divide and conquer method. what makes merge sort efficient for sorting a linked list?\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : it is really inefficient to access a certain index in a linked list, which is what many sorting algorithms rely on. mergesort, however, divides and merges lists, which lls do efficiently. you can find some code and an explanation here.\n",
      "\n",
      "--------------------------------------------------Answer No:8--------------------------------------------------\n",
      "title :  correct way to implement linked list\n",
      "\n",
      "\n",
      "question : i'm doing this challenge on hacker rank that wants me to implement a linked list.\n",
      "it seems to want me to find the last-added instance of node and change its head to link to my new instance of node. therefore the last instance added would have head=none (i'm using python).\n",
      "this is the pic they provide -\n",
      " \n",
      "wouldn't it make more sense to create a node instance with its head linked to the previous node? that way the only node with head=none would be the first node created.\n",
      "i've seen conflicting suggestions so far. i'm not a cs student or developer.\n",
      "edit -\n",
      "this example from youtube (1.36) suggests the second method.\n",
      "edit -\n",
      "sorry if this seemed like a programming question. i'm trying to see if there's a logical way to set up linked lists for my own benefit... solving the hackerrank challenge is not the issue.\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : one of the solutions can be:\n",
      "\n",
      "\n",
      "node* insert(node *head,int data)\n",
      "{\n",
      "node *p,*q;\n",
      "\n",
      "\n",
      "q=(struct node *)malloc(sizeof(struct node*));// allocating memory for new node\n",
      "if(q==null)\n",
      "{\n",
      "  printf(\"memory problem....\");  //return if memory can't be allocated\n",
      "  return 0;\n",
      "}\n",
      "q->data=data;                //put data in data portion of the new node\n",
      "q->next=null;                //the next link will point to null since it is getting added at the end of the list \n",
      "if(head == null)             //check out if the list is empty\n",
      "{\n",
      "    head=q;                  //if empty the new node will be 'head'\n",
      "}\n",
      "else\n",
      "{\n",
      "    p=head;\n",
      "    while(p->next != null)    // otherwise get to the end of the list\n",
      "    {\n",
      "        p=p->next;\n",
      "    }\n",
      "\n",
      "    p->next=q;                //last node of the list will point to the new node created\n",
      "\n",
      "}\n",
      " return head;                 \n",
      "\n",
      "}\n",
      "i have tested, it is working on hacker rank.\n",
      "whether the head is linked to previous or next it has to be singly linked list and we have to traverse to the end of the list for insertion of a node.\n",
      "i hope this is helpful to you....\n",
      "\n",
      "subanswer 2 : first of all, don't have a head pointer in your structure that doesn't point to the head of the list: it will confuse everyone. call the pointer in your structure next or something!\n",
      "you are right that in a singly-linked list (one with a next pointer but no pre pointer) it is illogical and inefficient to add new items to the end of the list. singly-linked lists work best when you add each new item to the beginning of the list. then all you need to do is:\n",
      "\n",
      "create a new item and fill in its data.\n",
      "set its next pointer to the value stored in the global head variable.\n",
      "set the global head variable to point to the new item.\n",
      "\n",
      "thus, as you say, only the first item to be added to the list will have next=null.\n",
      "adding items to the end of the list involves walking through the whole of the list every time, which is not efficient or sensible.\n",
      "if you wanted a singly linked list to which you could add items at the end, you would have a second global variable (call it tail) pointing to the last item in the list. this makes for inelegant code, since you now have different kinds of behaviour when tail is null (which it will be at the beginning) and when tail is not null. in fact, a good way of handling matters in this case is to create the list with one fictional item in it already, and tail pointing to that item. this saves a lot of tests, but you will of course have to remember, when walking through the list, not to pay attention to that fictional item.\n",
      "\n",
      "--------------------------------------------------Answer No:9--------------------------------------------------\n",
      "title :  using b-method, and formal methods in general, to model and verify a reverse linked list\n",
      "\n",
      "\n",
      "question : i am trying to do some formal modeling of a linked list, however instead of referencing the next block, each block needs to reference the previous block instead.\n",
      "is there already any formal methods or any formal for doing this ?\n",
      "exactly the same as a normal linked list but when a new block (value etc) is added this references the past value (much like the bitcoin blockchain).\n",
      "i have modeled a normal linked list (data queue) modeled in the b method \n",
      "machine dataqueue ( data , anydata , maxqueue )\n",
      "\n",
      "constraints anydata e data /\\ maxqueue > 0\n",
      "sees bool type\n",
      "sets token\n",
      "properties card ( token ) = maxqueue\n",
      "variables tokenseq , tokenmap\n",
      "\n",
      "invariant\n",
      "tokenseq e iseq ( token ) /\\\n",
      "tokenmap e token -|-> data /\\\n",
      "dom ( tokenmap )=  used\n",
      "initialisation\n",
      "tokenseq , tokenmap : [] , {}\n",
      "\n",
      "\n",
      "operations\n",
      "success , token <-- additem( item )  =^\n",
      "pre e item data then\n",
      "choice\n",
      "any new token where new_token  e token_used\n",
      "then\n",
      "tokenseq := tokenseq <-- new token ||\n",
      "tokenmap ( new token ) := item ||\n",
      "success , token := true , new token\n",
      "end\n",
      "or\n",
      "success := false || token :e token\n",
      "end\n",
      "end ;\n",
      "definitions\n",
      "used =^ ran ( tokenseq )\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : there are many approaches for verifying linked structures---arguably, more suitable than the b method---that you might want to use, depending on the language and properties you want to verify. most of the approaches rely on separation logic (which was in big part motivated for verification of linked structures).\n",
      "some tools include:\n",
      "\n",
      "full functional verification of linked data structures -- where you write java code with specifications in classical higher-order logic, while the verifier uses integrated reasoning of multiple different provers\n",
      "linked list, imperative separation logic in isabelle -- uses separation logic in isabelle theorem prover (other similar data structure examples might be found in the archive of formal proofs)\n",
      "dafny: a language and program verifier for functional correctness -- which allows specifying and verifying wide range of data structures in c# (many examples for linked lists exist, e.g. this one)\n",
      "\n",
      "to quote this answer (which answers a very similar question), even though you did not give details about what are you trying to verify, it seems that properties you might want to prove about the \"reverse linked list\" might be formulated as properties for a regular linked list. (if the reverse list requires some additional (non-standard) implementations, not already declared for the linked list, you might be able to model those in addition.)\n",
      "i am not sure what was the purpose of your example, but your code seems similar to an example of modelling a linked list with b (which includes other standard operations) method in program development by refinement case studies using the b method.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------Answer No:10--------------------------------------------------\n",
      "title :  question regarding linkedlist in java\n",
      "\n",
      "\n",
      "question : when i was reading a book for scjp, i came across the following paragraph.\n",
      "\n",
      "a linkedlist is ordered by index position, like arraylist, except that\n",
      "  the elements are doubly-linked to one another. this linkage gives you\n",
      "  new methods (beyond what you get from the list interface) for adding\n",
      "  and removing from the beginning or end, which makes it an easy choice\n",
      "  for implementing a stack or queue. keep in mind that a linkedlist may\n",
      "  iterate more slowly than an arraylist, but it's a good choice when you\n",
      "  need fast insertion and deletion..\n",
      "\n",
      "what makes a linkedlist to iterate more slowly than an arraylist ?\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : here is an answer from stackoverflow that explains it pretty well:\n",
      "https://stackoverflow.com/questions/716597/array-or-list-in-java-which-is-faster\n",
      "basically, the arraylist is contiguous where the linkedlist is not.  incrementing to the next location in memory with the arraylist is considered faster than jumping to the next location via a reference in linkedlist.  also, maintenance of the linkedlist would incur overhead to maintain two sets of references for a doubly linked list.\n",
      "\n",
      "subanswer 2 : i haven't looked at these classes in java but typically an array will be faster than a linked list because in a linked list the list is made up of a series of nodes which each of a \"link\" to the next node in the sequence.  so when you ask for the 10th element it has to cycle through 10 elements to pull the one you want.  in an array (unless i'm mistaken) calling for an element takes you straight to that element.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# getting the combined search results both semantic and the text based.\n",
    "answer_no = 1\n",
    "for i in search(\" what is a linked list ? \"):\n",
    "    print('-'*50 + \"Answer No:\" + str(answer_no) + '-'*50)\n",
    "    title = total_text_dictionary[i[1]][0]\n",
    "    question = total_text_dictionary[i[1]][1]\n",
    "    print(\"title : \" ,title )\n",
    "    print('\\n')\n",
    "    print(\"question :\" , question)\n",
    "    print('\\n')\n",
    "    sub_answer = 1\n",
    "    for i in total_text_dictionary[i[1]][2:]:\n",
    "        print(\"subanswer \" + str(sub_answer) +' : ' + i )\n",
    "        sub_answer+=1\n",
    "    answer_no+=1\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 0.315143346786499\n"
     ]
    }
   ],
   "source": [
    "print(\"Time Taken:\" , end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Modelling Using the Bert\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 ) Loading the Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using bert model\n",
    "import tensorflow as tf\n",
    "import tokenization\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "max_seq_length = 128  # Your choice here.\n",
    "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,name=\"input_word_ids\")\n",
    "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,name=\"input_mask\")\n",
    "segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,name=\"segment_ids\")\n",
    "bert_layer = hub.KerasLayer(\"bert_en_uncased_L-24_H-1024_A-16_2\")\n",
    "\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
    "from tensorflow.keras.models import Model\n",
    "bert_model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=pooled_output)\n",
    "\n",
    "def make_vector_bert(query):\n",
    "    def make_mask(tokens):\n",
    "        mask = []\n",
    "        for i in tokens:\n",
    "            if i != '[PAD]':\n",
    "                mask.append(1)\n",
    "            else:\n",
    "                mask.append(0)\n",
    "        return np.array(mask)\n",
    "    \n",
    "    tokens = tokenizer.tokenize(query)\n",
    "    if len(tokens) < 126:\n",
    "        tokens = [ '[CLS]' , *tokens ,  '[SEP]' , *['[PAD]']*(126 - len(tokens)) ]\n",
    "    else:\n",
    "        tokens = tokens[:126]\n",
    "        tokens = ['[CLS]' , *tokens , '[SEP]']\n",
    "    text = [np.array(tokenizer.convert_tokens_to_ids(tokens))]\n",
    "    segment = np.array([[0]*128])\n",
    "    mask =   [make_mask(tokens)]\n",
    "    embeddings = bert_model.predict([text , mask , segment])\n",
    "    vector = []\n",
    "    for i in embeddings[0]:\n",
    "        vector.append(float(i))\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ) Defining the Structure of the Elastic Search Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code reference from the elastic search documentation \n",
    "\n",
    "structure = {\"mappings\": {\n",
    "      \"properties\": {\n",
    "            \"total_texts\": {\n",
    "              \"type\": \"text\"\n",
    "            },\n",
    "            \"total_vectors\": {\n",
    "                  \"type\": \"dense_vector\",\n",
    "                \"dims\": 1024\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "ret = es.indices.create(index='database_bert', ignore=400, body=structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 ) Conneting to the Elastic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to ES!\n"
     ]
    }
   ],
   "source": [
    "# code reference from the elastic search documentation \n",
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n",
    "if es.ping():\n",
    "    print('Connected to ES!')\n",
    "else:\n",
    "    print('Could not connect!')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4) Indexing of the data into the elastic search or feeding the data to the elastic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating the bert enbedings:\n",
    "points = []\n",
    "for i in tqdm(total_text_dictionary.items()):\n",
    "    doc_id = i[0]\n",
    "    total_text = \" \".join(i[1])\n",
    "    point = {\"total_texts\":total_text ,\"total_vectors\" :make_vector_bert(total_text)\n",
    "    points.append(doc_id , point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the dictionary file\n",
    "with open('points_list.pickle', 'wb') as t:\n",
    "    pickle.dump(points,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('points_list.pickle', 'rb') as t:\n",
    "    points = pickle.load(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed...\n"
     ]
    }
   ],
   "source": [
    "# indexing of the data into the elastic search or feeding the data to the elastic search\n",
    "# inserting all the bert embeddings:\n",
    "for i in points:\n",
    "    doc_id , point = i\n",
    "    res = es.index(index=\"database_bert\", id=doc_id, body=point)\n",
    "print(\"Completed...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5) Defining the Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code reference from the elastic search documentation \n",
    "def search(query):\n",
    "\n",
    "    request={\n",
    "            'query':{ 'match':{\"total_texts\":query } }\n",
    "            }\n",
    "\n",
    "    res= es.search(index='database_bert',body=request)\n",
    "    l1 = []\n",
    "    for hit in res['hits']['hits']:\n",
    "        l1.append([hit['_score'] , hit['_id']])\n",
    "# change the cosine similarity to euclidean distance\n",
    "\n",
    "    query_vector = make_vector_bert(query)\n",
    "    request = {\"query\" : {\n",
    "                \"script_score\" : {\n",
    "                    \"query\" : {\n",
    "                        \"match_all\": {}\n",
    "                    },\n",
    "                    \"script\" : {\n",
    "                        \"source\": \"cosineSimilarity(params.query_vector, 'total_vectors') + 1.0\",\n",
    "                        \"params\": {\"query_vector\": query_vector}\n",
    "                    }\n",
    "                }\n",
    "             }\n",
    "    }\n",
    "\n",
    "    res= es.search(index='database_bert',body=request)\n",
    "    l2 = []\n",
    "    for hit in res['hits']['hits']:\n",
    "        l2.append([hit['_score'] , hit['_id']])\n",
    "    \n",
    "    l1 = norm_list(l1)\n",
    "    l2 = norm_list(l2)\n",
    "    \n",
    "    # getting the weighted average score for the text search and semantics search\n",
    "    temp_doc = {}\n",
    "    for i in l1:\n",
    "        temp_doc[i[1]]  = i[0]*2\n",
    "    for i in l2:\n",
    "        temp_doc[i[1]] = temp_doc.get(i[1] , 0) + i[0]*5\n",
    "    \n",
    "    inverse_temp_doc = [(i[1] , i[0])  for i in temp_doc.items()]\n",
    "    inverse_temp_doc = sorted(inverse_temp_doc , reverse = True)\n",
    "    return inverse_temp_doc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert Embeddings Results_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------Answer No:1--------------------------------------------------\n",
      "title :  why should leaf nodes in a red-black tree be black?\n",
      "\n",
      "\n",
      "question : from the property of red-black trees we know that: \n",
      "\n",
      "all leaves (nil) are black. (all leaves are same color as the root.)(comren et al \"introduction to algorithms\")\n",
      "\n",
      "\n",
      "but what is the reason that we should enforce them as black, even though they're nill's? \n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : take a uncolored leaf node, now you can color it as either red or black. if you colored it as red then you may have chance that your immediate ancestor is also red which is contradicting(according to basic principle). if you color it as black then no problem even though the immediate ancestor is red. and also no change in the number of black nodes from root to leaf paths(i.e every path get +1). this may be the possible reason behind that.\n",
      "\n",
      "subanswer 2 : it's simply a part of the definition of a red-black tree. it is also necessary to maintain one of the other rules associated with red-black trees: if a node is red, then both its children are black.\n",
      "\n",
      "--------------------------------------------------Answer No:2--------------------------------------------------\n",
      "title :  red black tree clarification\n",
      "\n",
      "\n",
      "question : i am quite new to red-black trees, and therefore i am having a bit of difficult time trying to understand them.\n",
      "one of the properties of the red-black tree is that every red vertex must have two black children, meaning one cannot have two consecutive red vertices.\n",
      "can someone explain to me why this is an essential property? what are the benefits of having such a property?\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : the properties of a red black tree allow insertion, deletion and search in $o(log(n))$. i guess you can find a prove online somewhere. \n",
      "when an element is inserted or deleted. a fix-up is done, it involves rotations in a tree, so the properties still hold. this ensures the tree is quitebalanced at all times and search is quite fast at all times.\n",
      "\n",
      "subanswer 2 : if you check the proof height-balancedness of red-black trees, you'll see that we essentially analyse the black-height $h_b$ of the tree which, by another important invariant, is the number of black nodes from the root to any leaf.\n",
      "the property you cite then gives us the right half of\n",
      "$\\qquad\\displaystyle h_b(t) \\leq h(t) \\leq 2h_b(t)$,\n",
      "which allows us to carry over bounds on black-height to usual height.\n",
      "\n",
      "--------------------------------------------------Answer No:3--------------------------------------------------\n",
      "title :  root color of a black red tree\n",
      "\n",
      "\n",
      "question : it is required that, in a black red tree, the color for the root is always black. however, wikipedia argues that this rule can be omitted as a red root can always be changed to black but not vice versa. i get the first half, that a red root can be changed to black at any time, but in what circumstance is it impossible to change a black node to red?\n",
      "for instance, consider the branch: black--red--black--red--black. we can always change it to red--black--black--red--black, since a black node does not need to have red children.\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : the root colour of a red-black tree carries no significance. in fact, you can save memory by not encoding it. didactically, it is meaningful to talk about a root's colour to illustrate what it means to be red or black, because it is a special case because it has no parent which is going to count it when it evaluates the sixth restriction in wikipedia's list (that the path from a particular node to a leaf should contain the same number of black nodes).\n",
      "as for your more general question about when changing a black node to a red one is allowed: a set of nodes can be repainted if afterwards, the black-height criterion is still satisfied. for example, if a row of the tree is saturated (if it is at depth $k$, there are $2^{k}$ nodes), then you can colour that row black. you may not colour only part of a (saturated or not) red row black. another example: in the tree $1:red \\rightarrow\\{ 2:black, 3:black\\rightarrow\\{4:red, 5:red\\}\\}$, you can flip the colours of $\\{3,4,5\\}$ and still have a legal rb tree. this is true generally for subtrees of even height and alternating colours. maybe you can think of more examples.\n",
      "\n",
      "--------------------------------------------------Answer No:4--------------------------------------------------\n",
      "title :  red-black tree. adding a red child to a red node with a black sibling\n",
      "\n",
      "\n",
      "question : according to my lecture notes, adding a red child to a red node with a black sibling in a red-black tree, is equivalent to changing a 3-node into a 4-node in a 2-3-4 tree. i've built several red-black trees with different values to try to get to this situation, but i never seem to get to the situation where i have a red node with a black sibling, and where the value to be inserted will be inserted below the red node. i'm starting to ask myself if this situation could ever happen in a red-black tree?\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : assume we have a black node $n$ with black child $l$ and red child $r$. thus we have a red and black sibling. recall that in a red-black tree all paths from root to leaf must have the same number of black nodes. the path $n-l$ contains two black nodes, the path $n-r$ just one. that means that both children of $r$ must be present, and must be black. so indeed, we can not add a new red child to $r$ because it already has black children. however, what can happen is that one of these black children turns red as consequence of a flag-flip. we then are in the situation you describe. \n",
      "\n",
      "--------------------------------------------------Answer No:5--------------------------------------------------\n",
      "title :  two red children in a red-black tree\n",
      "\n",
      "\n",
      "question : my data structures exam contains the following question:\n",
      "\n",
      "which of the statements below about red-black trees is true? (select one or more)\n",
      "\n",
      "every path from the root to a leaf has the same amount of red links.\n",
      "a node never has two red links to his childs.\n",
      "using a red-black tree, you can always draw the associated 2-3 tree.\n",
      "all leafs of a red-black tree are at the same height.\n",
      "\n",
      "\n",
      "the correct answer is: 2 and 3.\n",
      "i don't understand why a node can never have two red links to his child. on the image below (from wikipedia), i can see two red childs at node 25.\n",
      "could someone explain this to me?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : if 2 and 3 are both true, then the red-black trees you are sudying are not the standard ones, i.e., the ones from wikipedia.\n",
      "the red nodes are usually assumed to be \"satellites\" of the black node above. if there is at most one red node attached to a black one that means either one or to keays belong together (with altogether either two or three pointers to their children). that nicely corresponds to a 2-3 tree.\n",
      "the \"usual\" red-black trees can have two red children (but no red child to a red node) and correspond to 2-4 trees.\n",
      "\n",
      "--------------------------------------------------Answer No:6--------------------------------------------------\n",
      "title :  how can one search in o(log n) time in a red-black tree?\n",
      "\n",
      "\n",
      "question : how does the search operation for a red-black tree work and how does it take $o(\\log n)$ time, where $n$ is the number of items? i know a red-black tree takes $o(\\log n)$ recolorings and $o(1)$ rotations, but i was specifically interested in a good description of its search operation.\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : the search operation is the same for all binary search trees - recurse into the left or right branch depending on whether the element is smaller or larger than the current root. red-black trees are not special.\n",
      "the complexity of the search operation is equal to the height of the tree.\n",
      "different varieties of binary search trees differ in what guarantees on height of the tree they give, and in how exactly they maintain these guarantees. red-black trees and avl trees give you guaranteed o(log n) height, which is why search is o(log n).\n",
      "\n",
      "--------------------------------------------------Answer No:7--------------------------------------------------\n",
      "title :  red black tree and 2-3-4 tree isomorphism\n",
      "\n",
      "\n",
      "question : are all cases of addition and removal in 2-3-4 trees isomorphic to cases of addition and removal in red black trees?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "subanswer 1 : it depends what you mean by isomorphic. indeed a black node with its (zero, one or two) children corresponds to a 2-3-4 node (with 1,2,3 keys and 2,3,4 children). the basic operations on the two types of trees are really different but translate quite well. \n",
      "there is a single difference in symmetry: there is only one type of 3-node (2 keys, 3 children), whereas in a red-black tree the red child to the black node may be at the left or right side.\n",
      "\n",
      "--------------------------------------------------Answer No:8--------------------------------------------------\n",
      "title :  why are red-black trees so popular?\n",
      "\n",
      "\n",
      "question : it seems that everywhere i look, data structures are being implemented using red-black trees (std::set in c++, sorteddictionary in c#, etc.)\n",
      "having just covered (a,b), red-black & avl trees in my algorithms class, here's what i got out (also from asking around professors, looking through a few books and googling a bit):\n",
      "\n",
      "avl trees have smaller average depth than red-black trees, and thus searching for a value in avl tree is consistently faster.\n",
      "red-black trees make less structural changes to balance themselves than avl trees, which could make them potentially faster for insert/delete. i'm saying potentially, because this would depend on the cost of the structural change to the tree, as this will depend a lot on the runtime and implemntation (might also be completely different in a functional language when the tree is immutable?)\n",
      "\n",
      "there are many benchmarks online that compare avl and red-black trees, but what struck me is that my professor basically said, that usually you'd do one of two things:\n",
      "\n",
      "either you don't really care that much about performance, in which case the 10-20% difference of avl vs red-black in most cases won't matter at all.\n",
      "or you really care about performance, in which you case you'd ditch both avl and red-black trees, and go with b-trees, which can be tweaked to work much better (or (a,b)-trees, i'm gonna put all of those in one basket.)\n",
      "\n",
      "the reason for that is because a b-tree stores data more compactly in memory (one node contains many values) there will be much fewer cache misses. you could also tweak the implementation based on the use case, and make the order of the b-tree depend on the cpu cache size, etc.\n",
      "the problem is that i can't find almost any source that would analyze real life usage of different implementations of search trees on real modern hardware. i've looked through many books on algorithms and haven't found anything that would compare different tree variants together, other than showing that one has smaller average depth than the other one (which doesn't really say much of how the tree will behave in real programs.)\n",
      "that being said, is there a particular reason why red-black trees are being used everywhere, when based on what is said above, b-trees should be outperforming them? (as the only benchmark i could find also shows http://lh3lh3.users.sourceforge.net/udb.shtml, but it might just be a matter of the specific implementation). or is the reason why everyone uses red-black trees because they're rather easy to implement, or to put it in different words, hard to implement poorly?\n",
      "also, how does this change when one moves to the realm of functional languages? it seems that both clojure and scala use hash array mapped tries, where clojure uses a branching factor of 32.\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : red-black or avl trees have an advantage over b-trees and the like when the key is long or for some other reason moving a key is expensive.\n",
      "i created my own alternative to std::set within a major project, for a number of performance reasons.  i chose avl over red-black for performance reasons (but that small performance enhancement was not the justification for rolling my own instead of std::set).  the \"key\" being complicated and hard to move was a significant factor.  do (a,b) trees still make sense if you need another level of indirection in front of the keys?  avl and red-black trees can be restructured without moving keys, so they have that advantage when keys are expensive to move.\n",
      "\n",
      "subanswer 2 : to quote from the answer to “traversals from the root in avl trees and red black trees” question\n",
      "\n",
      "for some kinds of binary search trees, including red-black trees but\n",
      "  not avl trees, the \"fixes\" to the tree can fairly easily be predicted\n",
      "  on the way down and performed during a single top-down pass, making\n",
      "  the second pass unnecessary. such insertion algorithms are typically\n",
      "  implemented with a loop rather than recursion, and often run slightly\n",
      "  faster in practice than their two-pass counterparts.\n",
      "\n",
      "so a redblack tree insert can be implemented without recursion, on some cpus recursion is very expensive if you overrun the function call cache  (e.g sparc due to is use of register window) \n",
      "(i have seen software run over 10 times as fast on the sparc by removing one function call, that resulted in a often called code path being too deep for the register window.   as you don't know how deep the register window will be on your customer's system, and you don't know how far down the call stack you are in the \"hot code path\", not using recursion make like more predictable.)\n",
      "also not risking running out of stack is a benefit.\n",
      "\n",
      "subanswer 3 : well, this is not an authoritative answer, but whenever i have to code a balanced binary search tree, it's a red-black tree.  there are a few reasons for this:\n",
      "1) average insertion cost is constant for red-black trees (if you don't have to search), while it's logarithmic for avl trees.  furthermore, it involves at most one complicated restructuring.  it's still o(log n) in the worst case, but that's just simple recolorings.\n",
      "2) they require only 1 bit of extra information per node, and you can often find a way to get that for free.\n",
      "3) i don't have to do this very often, so every time i do it i have to figure it out how to do it all over again.  the simple rules and the correspondence with 2-4 trees makes it seem easy every time, even though the code turns out to be complicated every time.   i still hope that someday the code will turn out simple.\n",
      "4) the way the red-black tree splits the corresponding 2-4 tree node and inserts the middle key into the parent 2-4 node just by recoloring is super elegant.  i just love to do it. \n",
      "\n",
      "subanswer 4 : i've been researching this topic recently as well, so here are my findings, but keep in mind that i am not an expert in data structures!\n",
      "there are some cases where you can't use b-trees at all. \n",
      "one prominent case is std::map from c++ stl. the standard requires that insert does not invalidate existing iterators\n",
      "\n",
      "no iterators or references are invalidated.\n",
      "\n",
      "http://en.cppreference.com/w/cpp/container/map/insert\n",
      "this rules out b-tree as an implementation because insertion would move around existing elements.\n",
      "another similar use case are intrusive datastructures. that is, instead of storing your data inside the node of the tree, you store pointers to children/parents inside your structure:\n",
      "// non intrusive\n",
      "struct node<t> {\n",
      "    t value;\n",
      "    node<t> *left;\n",
      "    node<t> *right;\n",
      "};\n",
      "using walruslist = node<walrus>;\n",
      "\n",
      "// intrusive\n",
      "struct walrus {\n",
      "    // tree part\n",
      "    walrus *left;\n",
      "    walrus *right;\n",
      "\n",
      "    // object part\n",
      "    int age;\n",
      "    food[4] stomach;\n",
      "};\n",
      "\n",
      "you just can't make a b-tree intrusive, because it is not a pointer-only data structure. \n",
      "intrusive red-black trees are used, for example, in jemalloc to manage free blocks of memory. this is also a popular data structure in the linux kernel.\n",
      "i also believe that \"single pass tail recursive\" implementation is not the reason for red black tree popularity as a mutable data structure. \n",
      "first of all, stack depth is irrelevant here, because (given $\\log{n}$ height) you would run out of the main memory before you run out of stack space. jemalloc is happy with preallocating worst case depth on the stack.\n",
      "there are a number of flavors of red-black tree implementation. a famous one are left leaning red black trees by robert sedgewick (caution! there are other variants which also are named \"left leaning\", but use a different algorithm). this variant indeed allows to perform rotations on the way down the tree, but it lack the important property of $o(1)$  amortized number of fixups, and this makes it slower (as measured by the author of jemalloc). or, as opendatastrutures puts it\n",
      "\n",
      "andersson's variant of red-black trees, sedgewick's variant of red-black trees, and avl trees are all simpler to implement than the redblacktree structure defined here. unfortunately, none of them can guarantee that the amortized time spent rebalancing is $ o(1)$ per update. \n",
      "\n",
      "the variant described in opendatastructures uses parent pointers, a recursive down pass for insertion and an iterative loop up pass for fixups. the recursive calls are in a tail positions and compilers optimize this to a loop (i've checked this in rust). \n",
      "that is, you can get a constant memory loop implementation of a mutable search tree without any red-black magic  if you use parent pointers. this works for b-trees as well. you need magic for single pass tail recursive immutable variant, and it will break $o(1)$ fixup anyway.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------Answer No:9--------------------------------------------------\n",
      "title :  traversals from the root in avl trees and red black trees\n",
      "\n",
      "\n",
      "question : we all know that for insertion() operation in avl tree following can happen:\n",
      "we traverse down the tree from root to appropriate node and there insert the key and then for maintaining height balance we have to check heights of the ancestors of the newly inserted node and in doing so, we could end up traversing up to the root.\n",
      "i completely agree with this.\n",
      "but according to me the same can happen in red black tree because first we would traverse down the tree to appropriate node and then insert the key.then there is a possibility that a series of rotation and flip color operations could make us traverse the path up to the root.\n",
      "now my question is : why following statement is right?\n",
      "\n",
      "in avl tree insert() operation, we first traverse from root to newly inserted node and then from newly inserted node to root. while in red black tree insert(), we only traverse once from root to newly inserted node.\n",
      "\n",
      "it came as a question, which of the following statements is right about avl and red black trees and the option with given statement was marked correct in the answer key. i am trying to figure out mistake in my second observation?\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : for virtually all kinds of binary search trees, including avl trees and red-black trees, you can implement insertion in what is called a bottom-up fashion.  this involves two passes through the tree: the first pass starting at the root and moving down the tree to find the right place to do the insertion, and the second pass starting at the insertion point and moving upward toward the root fixing the tree as necessary.  frequently, these two passes are implemented as one recursive function, where the first pass is going down the recursion, and the second pass is coming back out of the recursion.\n",
      "for some kinds of binary search trees, including red-black trees but not avl trees, the \"fixes\" to the tree can fairly easily be predicted on the way down and performed during a single top-down pass, making the second pass unnecessary.  such insertion algorithms are typically implemented with a loop rather than recursion, and often run slightly faster in practice than their two-pass counterparts.\n",
      "note that, for trees like red-black trees, where you can implement insertion either way, the two different approaches (bottom-up/two-pass vs top-down/one-pass) do not necessarily yield exactly the same tree, but will yield trees that are equivalent.  for example, the exact pattern of red and black nodes may vary slightly, but will still obey all the expected invariants of a red-black tree. \n",
      "\n",
      "--------------------------------------------------Answer No:10--------------------------------------------------\n",
      "title :  insertions in red-black trees\n",
      "\n",
      "\n",
      "question : i studied methods for inserting new nodes into red-black trees for the first time this month.\n",
      "in doing so, i read a lot of pages on the internet and found that ( if i'm not mistaken ) there are many, many, many accepted algorithms for inserting nodes into red-black trees.\n",
      "furthermore, i noticed that it is possible to have two insertion algorithms that don't break red-black tree invariants, but also can start with the same initial tree, insert the same node, and end up with different resulting trees.\n",
      "i think.\n",
      "for example, take this website's algorithm for insertion:\n",
      "https://www.cs.usfca.edu/~galles/visualization/redblack.html\n",
      "and then there's this famous example from 'purely functional data structures' by chris okasaki:\n",
      "\n",
      "and then there's this algorithm from ohio state:\n",
      "https://www.pdf-archive.com/2017/03/28/08-red-black-tree/08-red-black-tree.pdf\n",
      "is it true that there are many red-black tree insertion algorithms that, given the same domain, will map the elements in that domain differently?\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : yes, a given set can be represented by multiple red-black trees, and this works incrementally, at least some of the time.  that is, there exists more than one valid red-black tree insertion algorithm, whose outputs are not always equal.\n",
      "the easiest way of seeing this is to focus on the correspondence between red-black trees and $(2, 4)$-b-trees.  a black node with its red children correspond to a b-tree node.\n",
      "in particular, if you have two sibling b-tree nodes with four elements in total, they can be distributed 1/3 or 2/2.  in red-black terms, if two black nodes are cousins, it's possible for each to have one red child, or for one of them to have two red children and the other to have none.  more than that, you can shuffle the elements around between the nodes locally to transform one such pattern into the other.\n",
      "as wikipedia says, \"the balancing of the tree is not perfect, but it is good enough to allow it to guarantee searching in o(log n) time\"; the imperfection of balancing gives room for multiple tree representations of the same set.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# getting the combined search results both semantic and the text based.\n",
    "answer_no = 1\n",
    "for i in search(\"what is red black trees\"):\n",
    "    print('-'*50 + \"Answer No:\" + str(answer_no) + '-'*50)\n",
    "    title = total_text_dictionary[i[1]][0]\n",
    "    question = total_text_dictionary[i[1]][1]\n",
    "    print(\"title : \" ,title )\n",
    "    print('\\n')\n",
    "    print(\"question :\" , question)\n",
    "    print('\\n')\n",
    "    sub_answer = 1\n",
    "    for i in total_text_dictionary[i[1]][2:]:\n",
    "        print(\"subanswer \" + str(sub_answer) +' : ' + i )\n",
    "        sub_answer+=1\n",
    "    answer_no+=1\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert Embeddings Results_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------Answer No:1--------------------------------------------------\n",
      "title :  how hash-table and hash-map are different?\n",
      "\n",
      "\n",
      "question : in the context of cs, how the hash-table and hash-map are different? \n",
      "i was watching a part of \"algorithm with swift\" video in udacity, and i discovered the terms \"hash-table\" and \"hash-map\" are somewhat confusing.\n",
      "as far as i understand, \n",
      "\n",
      "hash table → stores keys only → swift set.\n",
      "hash map → stores key/value pairs → swift dictionary.\n",
      "\n",
      "but, wikipedia is talking hash-table is same thing with hash-map. here i could not find any help.\n",
      "is this formal or widely accepted cs term? am i understanding correctly? if i'm wrong, please correct me. thanks.\n",
      "\n",
      "i know industry uses their own terms that can be different, and i am asking about academia because i believe terms are more consistent in academia. if it's not, i just would abandon to learn academic terms.\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : if you ask me, you're correct and wikipedia is wrong, as the complaints on the article's talk page (some 11 years ago!) clearly explain, but it was never fixed (or it was fixed and reverted).\n",
      "a hash table stores items; these items can be keys (in which case it implements a set), or key-value pairs (in which case it implements a map, i.e. a hash map), or perhaps something else, e.g. triples; the wikipedia article describes only the key-value case, while i was only taught the key-only case in class.\n",
      "some people do use hash table to mean hash map, so wikipedia successfully describes a particular usage of the term; it should also describe the other cases. (it does describe how a hash map can be used to implement a set and other data structures, but that's not the same thing.)\n",
      "in it, most terms mean different things to different people, and most people using the term in one sense aren't aware that other people use it in another sense; hash table is no exception.\n",
      "\n",
      "--------------------------------------------------Answer No:2--------------------------------------------------\n",
      "title :  why does hashmap allow only one null key?\n",
      "\n",
      "\n",
      "question : a hashmap allows only one null key. is it because it allows only unique keys?  or is there another reason?\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : why is it confusing? the javadoc for hashmap.put clearly states:\n",
      "\n",
      "associates the specified value with the specified key in this map. if the map previously contained a mapping for the key, the old value is replaced.\n",
      "\n",
      "it clearly states what happens when you do a put with a key which was already in the map. the specific case of key == null behaves in the same way: you can't have two different mappings for the null key (just like you can't for any other key). it's not a special case, for the context of your question.\n",
      "\n",
      "--------------------------------------------------Answer No:3--------------------------------------------------\n",
      "title :  why isn't an edge-map graph implementation used in practice?\n",
      "\n",
      "\n",
      "question : wikipedia states that three different graph implementations that are used in practice:\n",
      "\n",
      "adjacency lists\n",
      "adjacency matrix\n",
      "incidence matrix\n",
      "\n",
      "while i was learning about these structures, another implementation occurred to me that seems to have better asymptotic properties than wikipedia's. my idea is to create a hash map where the keys are (vertex, vertex) pairs and the values are the cost of their edge.\n",
      "given that inserting into and querying from a hash map is $o(1)$, i believe the time complexity would be the following:\n",
      "\n",
      "store graph: $o(e)$\n",
      "add vertex: $o(1)$\n",
      "add edge: $o(1)$\n",
      "remove vertex: $o(v)$\n",
      "remove edge: $o(1)$\n",
      "query cost between vertices: $o(1)$\n",
      "\n",
      "since this implementation has strictly better time and space complexity then all three options listed, i'm confused as to why this option isn't.\n",
      "why isn't this implementation used in practice?\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : assume we are dealing with the representation of a weighted graph. i will use python as the programming language to illustrate the points, which will remain true largely if another programming language is used.\n",
      "let us call the graph representation raised in the question \"hashmap from edges to their weights\" or \"edge-weight hashmap\". i would agree that an edge-weight hashmap is seldom used to represent a weighted graph. \n",
      "one overwhelming reason is that compared to edge-weigh hashmap, it is usually preferred to use the following popular variation of adjacency list, which i will call \"adjacent hashmaps\" or \"nested hashmaps\". the entire graph is represented by a big hashmap $g$, a.k.a. the outer hashmap, which is a collection of $(v, g[v])$ pairs, where $v$ is a vertex and $g[v]$ is a smaller hashmap, a.k.a. the inner hashmap. $g[v]$ is a collection of of $(u, w)$ pairs, where each vertex $u$ is a vertex that is adjacent to $v$ and $w$ is the weight of edge $(v,u)$.\n",
      "an example\n",
      " \n",
      "$\\begin{array}{c|c}\n",
      " \\text{nested hashmap} & \\text{edge-weight hashmap} \\\\\\hline\n",
      "  \\begin{array}{l@{}l@{}l@{}lll}\n",
      "\\{\\\\\n",
      "\\quad1: &\\{2:2,&4:5\\},\\\\\n",
      "\\quad2: &\\{1:2, &3:14, &4:5, &5:4\\},\\\\\n",
      "\\quad3: &\\{2:14,&5:34\\},\\\\\n",
      "\\quad 4: &\\{1:5, &2:5, &5:58\\},\\\\\n",
      "\\quad 5: &\\{2:4, &3:34, &4:58\\}\\\\\n",
      "\\}\\end{array}                & \n",
      "\\begin{array}{lllll}\n",
      "\\{\\\\\n",
      "\\quad(1,2):2,           &(1,4):5,\\\\\n",
      "\\quad(2,1):2, &(2,3):14,&(2,4):5,&(2,5):5,\\\\\n",
      "\\quad(3,2):14,&(3,5):34,\\\\\n",
      "\\quad(4,1):5, &(4,2):5, &(4,5):58,\\\\\n",
      "\\quad(5,2):4, &(5,3):34,&(5,4):58\\\\\n",
      "\\}\\end{array} \\\\\n",
      "\\end{array}$\n",
      "the alignment of data entries above is meant for easy reading of python code. by the general nature of hashmap, the actual storage locations of the entries in a hashmap are sort of unpredictable.\n",
      "comparison of complexity between nested hashmaps and edge-weight hashmap \n",
      "$\\begin{array}{|l|c|c|}\\hline\n",
      "&\\text{nested hashmap} & \\text{edge-weight hashmap}\\\\\\hline \n",
      "\\text{store graph} &o(|e|) &o(|e|)\\\\\\hline\n",
      "\\text{add vertex} &o(1) &o(1)\\\\\\hline\n",
      "\\text{add edge} &o(1) &o(1)\\\\\\hline\n",
      "\\text{remove vertex} &o(|v|)&o(|v|)\\\\\\hline\n",
      "\\text{remove edge} &o(1) &o(1)\\\\\\hline\n",
      "\\text{check if two vertices are adjacent} &o(1) &o(1)\\\\\\hline\n",
      "\\text{list neighborhood of a vertex }&o(|v|) &?\\ o(|e| )\\ ?\\\\\\hline\n",
      "\\end{array}$\n",
      "the entry \"$?\\ o(|e| )\\ ?$\" entry on the column of \"edge-weight hashmap\" means that it is not clear how to list neighborhood of a given vertex $v$ efficiently. $o(|e|)$ refers to the time-complexity of the natural way, which goes over all the edges, keeping only the edges that contain $v$.\n",
      "so both implementations have the same asymptotic time-complexity and space-complexity for all operations, except for listing the neighborhood of a vertex, arguably the most popular iteration on a graph, for which nested hashmaps are significantly faster. in practice, nested hashmaps should also exhibit better cache-friendliness. \n",
      "comparison of programming friendliness\n",
      "here are the code that does the basic iterations over a graph represented in variable $g$ using nested hashmap or edge-weight hashmap.\n",
      "$\\begin{array}{|l|l|c|}\\hline\n",
      "&\\text{nested hashmap} & \\text{edge-weight hashmap}\\\\\\hline \n",
      "\\text{iterate over all vertices} &\\text{for v in g:} &???\\\\\\hline\n",
      "\\text{iterate over the neighborhood of vertex u} &\\text{for v in g[u]:} &???\\\\\\hline\n",
      "\\text{iterate over all edges} &\\begin{array}{c}\\text{for u in g:}\\quad\\quad\\\\\\text{ for v in g[u]:}\\end{array} &\\text{for e in g:}\\\\\\hline\n",
      "\\end{array}$\n",
      "the \"???\" entries on the column of \"edge-weight hashmap\" means that it seems rather clumsy to write that piece of code in python or other programming languages, assuming their generally-available implementations of hashmap.\n",
      "nested hashmaps are far more programmer-friendly than edge-weight hashmap.  \n",
      "summary\n",
      "although the time-complexity of the most basic operations using edge-weight hashmap are very good, it does not support the basic iterations well. it should be replaced by nested hashmaps in general.\n",
      "exercises\n",
      "exercise 1. verify that this answer is applicable for weighted directed graph after slight adaptation. verify that this answer is applicable for (unweighted) directed or undirected graph as well. \n",
      "exercise 2. compare edge-weight hashmap with adjacent-weight list in detail. an adjacent-weight list for the graph above in python can be $g=[[], [(2,2), (4,2)],$ $[(1,2), (3,14), (4,5), (5,5)],$ $[(2,14), (5, 34)],$ $[(1,5), (2,5), (5,58)],$ $[(2,4), (3,34), (4,58)]]$, where $g[v]$ is a list of $(u,w)$ pairs for vertex $v=1,2,3,4,5$ (g[0] is ignored since 0 is not a vertex), where $w$ is the weight of edge $(v,u)$. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "subanswer 2 : there's at least two points that should be raised here: \n",
      "\n",
      "insert and query for a hash table are not in general constant time operations in the worst case. \n",
      "there is typically no implementation that would be suitable for every possible case (i.e., different algorithms might benefit from different implementations of the graph). as an example, it doesn't seem clear how you would efficiently iterate over the neighbors of a vertex which several graph algorithms need.\n",
      "\n",
      "\n",
      "--------------------------------------------------Answer No:4--------------------------------------------------\n",
      "title :  can you insert into sorted list with time o(1)?\n",
      "\n",
      "\n",
      "question : wondering if this was possible. if i have a sorted list, can i find the right spot for an integer and insert it, all in o(1) time? the only way i can think to do this is via having a massive hashmap with one slot for each possible integer. 2 billion different integers * 4 bytes per integer = 8 gigabytes....but it'd technically work. there has to be a better way to do this though, right?\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : one thing before i explain: hashmap doesn't use an array that big, it uses chaining, which is another concept you'll have to look up. and if you're talking about creating an array size 2 billion, that still won't work because you still have to scan the 2 billion entries in the array. ok, technically that's o(1), but only because o(2 billion) is counted as o(1).\n",
      "i actually wondered about this for a long time. if you think about it, there is no possible way even with the hashmap. before i get into why hashmap doesn't work, if you don't use a hashmap, you'll have to scan the whole size that you have to insert. now to the hashmap part, after inserting you're number, you'll have to update every entry after that. and if you don't, you'll get an o(1) insertion once, but after that you'll get wrong insertions.\n",
      "\n",
      "subanswer 2 : sounds like you want a solution for bounded integers, 32-bit for example. if so, any sorted dictionary whose complexity depends on the key length only will do what you want. two examples are binary trie and van emde boas tree.\n",
      "\n",
      "--------------------------------------------------Answer No:5--------------------------------------------------\n",
      "title :  java.util.hashmap lock on actual hashmap object compare to lock on object that encapsulate the hashmap\n",
      "\n",
      "\n",
      "question : the below javadoc is an snippet of hashmap documentation. why authors would emphasize on putting a lock on the object that encapsulate a hashmap? lock on the actual hashmap object makes for sense. \n",
      "\n",
      "note that this implementation is not synchronized. if multiple threads access a hash map concurrently, and at least one of the threads modifies the map structurally, it must be synchronized externally. (a structural modification is any operation that adds or deletes one or more mappings; merely changing the value associated with a key that an instance already contains is not a structural modification.) this is typically accomplished by synchronizing on some object that naturally encapsulates the map. if no such object exists, the map should be \"wrapped\" using the collections.synchronizedmap method...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : encapsulation is necessary here in order to restrict direct access of client code to methods of hashmap.\n",
      "as for recommendation on what object to use as a lock, it serves a purpose to allow client code to iterate over the map in a thread safe way.\n",
      "if you intend your map to be synchronized but lock on actual hashmap object, without hiding (encapsulating) it, then any code having access to that object would be able to invoke its unsynchronized methods and break synchronization. purpose of encapsulation in this case is stated further in javadocs you refer: \"to prevent accidental unsynchronized access to the map\".\n",
      "documentation also refers to collections.synchronizedmap as an example on how one is expected to synchronize:\n",
      "\n",
      "returns a synchronized (thread-safe) map backed by the specified map. in order to guarantee serial access, it is critical that all access to the backing map is accomplished through the returned map...\n",
      "\n",
      "you see, synchronizedmap documentation reiterates the importance (\"it is critical\") for the client code not accessing \"backing map\" directly.\n",
      "this documentation also further provides the example explaining why it is recommended to synchronize on the enclosing object:\n",
      "\n",
      "it is imperative that the user manually synchronize on the returned map when iterating over any of its collection views:\n",
      "  map m = collections.synchronizedmap(new hashmap());\n",
      "      ...\n",
      "  set s = m.keyset();  // needn't be in synchronized block\n",
      "      ...\n",
      "  synchronized (m) {  // synchronizing on m, not s!\n",
      "      iterator i = s.iterator(); // must be in synchronized block\n",
      "      while (i.hasnext())\n",
      "          foo(i.next());\n",
      "  }\n",
      "\n",
      "failure to follow this advice may result in non-deterministic behavior. \n",
      "\n",
      "you see, in the above code example, if client code would not have access to \"known by convention\" lock object, it would be impossible to properly synchronize: some other code could have used other lock to wrap the iteration which would lead to unsynchronized access.\n",
      "\n",
      "subanswer 2 : i understand it as saying that an \"easy\" way is to use the synchronized wrappers or make the class holding the map synchronized (i.e. using synchronized methods, which is what the wrappers does essentially).\n",
      "but there are other ways, such as synchronising on the map itself if it is private and final, using a separate lock object or using a concurrentmap. i wouldn't overthink what is said here and simply apply usual concurrency patterns.\n",
      "\n",
      "--------------------------------------------------Answer No:6--------------------------------------------------\n",
      "title :  does making the keys of a hashtable the same length make the hashtable any better?\n",
      "\n",
      "\n",
      "question : the question popped up in my head. the hash function used is murmur3.\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : it makes the hash table unusable if i can’t have x and yz and abc as keys. \n",
      "\n",
      "--------------------------------------------------Answer No:7--------------------------------------------------\n",
      "title :  what is the difference between a hash and a dictionary?\n",
      "\n",
      "\n",
      "question : what is the difference between hash and dictionary? \n",
      "coming from a scripting background, i feel that they are similar, but i wanted to find out the exact differences. googling did not help me much. \n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : \"dictionary\" is the name of the concept. a hashtable is a possible implementation.\n",
      "\n",
      "subanswer 2 : a dictionary is the collective term given for any data structure implementation used for fast lookups/insertions. this can be achieved/implemented using a variety of data structures like hash table, skip lists, rb tree etc. a hash table is a specific data structure useful for many purposes including implementing a dictionary.\n",
      "\n",
      "subanswer 3 : a dictionary uses a key to reference the value directly inside of an associative array.\n",
      "i.e (key => value)\n",
      "a hash is more often described as a hash table which uses a hash function to calculate the position in memory (or more easily an array) where the value will be. the hash will take the key as input and give a value as output. then plug that value into the memory or array index.\n",
      "i.e key => hash function => value\n",
      "i guess one is direct while the other isn't. hash functions may not be perfect either and may sometimes provide an index referencing the wrong value. but that can be corrected.\n",
      "best place to look: wikipedia (associative array and hash table)\n",
      "\n",
      "subanswer 4 : hash is an extremely poorly named data structure where the programmer has confused the interface with implementation (and was too lazy to write the full name, i.e. hashtable instead resorting to an abbreviation, hash).\n",
      "dictionary is the “correct” name of the interface (= the adt), i.e. an associative container that maps (usually unique) keys to (not necessarily unique) values.\n",
      "a hash table is one possible implementation of such a dictionary that provides quite good access characteristics (in terms of runtime) and is therefore often the default implementation.\n",
      "such an implementation has two important properties:\n",
      "\n",
      "the keys have to be hashable and equality comparable.\n",
      "the entries appear in no particular order in the dictionary.\n",
      "\n",
      "(for a key to be hashable means that we can compute a numeric value from a key which is subsequently used as an index in an array.)\n",
      "there exist alternative implementations of the dictionary data structure that impose an ordering on the keys – this is often called a sorted dictionary (and is usually implemented in terms of a search tree, though other efficient implementations exist).\n",
      "\n",
      "to summarize: a dictionary is an adt that maps keys to values. there are several possible implementations of this adt, of which the hash table is one. hash is a misnomer but in context it’s equivalent to a dictionary that is implemented in terms of a hash table.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------Answer No:8--------------------------------------------------\n",
      "title :  why define a java object using interface (e.g. map) rather than implementation (hashmap)\n",
      "\n",
      "\n",
      "question : in most java code, i see people declare java objects like this:\n",
      "map<string, string> hashmap = new hashmap<>();\n",
      "list<string> list = new arraylist<>();\n",
      "\n",
      "instead of:\n",
      "hashmap<string, string> hashmap = new hashmap<>();\n",
      "arraylist<string> list = new arraylist<>();\n",
      "\n",
      "why is there a preference to define the java object using the interface rather than the implementation that is actually going to be used?\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : having the variable constrained to an interface ensures none of the usages of that variable will be using hashmap specific functionality that may not exist on the interface, so the instance may be changed without concern later to a different implementation so long as the new instance also implements the interface.\n",
      "for this reason, anytime you want to use an objects interface, it is always good practice to declare your variables as the interface and not the particular implementation, this goes for all types of objects you may use which have an interface. the reason you see it often is many people have built this in as a habit.\n",
      "that said, it's not harmful to skip out of using interfaces sometimes, and most of us sloppily don't always follow this rule, with no real harm. it's just a good practice to stick to when you have any feeling the code may be changed and need maintenance/growth in the future. it's less of a concern when you're hacking on code you don't suspect will have a long life or has much importance. also breaking this rule usually has a small consequence  that changing the implementation to another one may require a bit of refactoring, so if you don't always follow it you won't hurt yourself a lot, though there's no real harm in following it either.\n",
      "\n",
      "subanswer 2 : the reason is that the implementation of these interfaces is usually not relevant when handling them, therefore if you oblige the caller to pass a hashmap to a method, then you're essentially obliging which implementation to use.  so as a general rule, you're supposed to handle its interface rather than the actual implementation and avoid the pain and suffering which might result in having to change all method signatures using hashmap when you decide you need to use linkedhashmap instead.\n",
      "it should be said that there are exceptions to this when implementation is relevant.  if you need a map when order is important, then you can require a treemap or a linkedhashmap to be passed, or better still sortedmap which doesn't specify a specific implementation. this obliges the caller to necessarily pass a certain type of implementation of map and strongly hints that order is important.  that said, could you override sortedmap and pass an unsorted one?  yes, of course, however expect bad things to happen as a result.\n",
      "however best practice still dictates that if it isn't important, you shouldn't use specific implementations.  this is true in general.  if you're dealing with dog and cat which derive from animal, in order to make best use of inheritance, you should generally avoid having methods specific to dog or cat.  rather all methods in dog or cat should override methods in animal and it will save you trouble in the long run.\n",
      "\n",
      "subanswer 3 : it's to follow the interface segregation principle (the 'i' in solid).  it prevents code that uses those objects from depending on methods of those objects it doesn't need, which makes the code less coupled, and therefore easier to change.\n",
      "for example, if you find out later you really need a linkedhashmap, you can safely make that change without affecting any other code.\n",
      "however, there's a trade off, because you're artificially limiting the code that can take your object as a parameter.  say there's a function somewhere that requires a hashmap for some reason.  if you return a map, you can't pass your object into that function.  you have to balance the likelihood of sometime in the future needing the extra functionality that's in the more concrete class  with the desire to limit coupling and keep your public interface as small as possible.\n",
      "\n",
      "subanswer 4 : in layman's words:\n",
      "the same reason electric apliances makers built their products with electrical plugs instead of simply peeled out cables, and houses come with wall sockets instead of peel out cables sticking out of the wall.\n",
      "by using standard plugs instead, they allow to plug the same apliances in any compatible plug around the house.\n",
      "from the point of view of the wall socket, it doesn't matter whether you plug a tv set or a stereo.\n",
      "that makes both the appliance and the socket more useful.\n",
      "take for example a method that accepts a map as an argument.\n",
      "the method willl work regardless of you passing a hashmap or a linkedhashmap to it, as long it's a subclass of map.\n",
      "that's liskov substitution principle.\n",
      "in the sample code you gave, it means you can later, for some reason, change the concrete implementation of hash and you will not need to change the rest of the code.\n",
      "the problem with software is that, since it's relatively easy to change things later with no waste of bricks or mortar, people assume that kind of fore-thought is not worth the while. but reality has showed us that software maintenance is very expensive.\n",
      "\n",
      "--------------------------------------------------Answer No:9--------------------------------------------------\n",
      "title :  history/etymology- map/[hash]map vs map()\n",
      "\n",
      "\n",
      "question : forgive me/delete this question if it doesn't qualify as computer science:\n",
      "i've always wondered about the relationship between map the data structure and map() the function. i know they are two different things. why share the name?\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : well, i am only a beginning msc student in computerscience but if if followed the classes correctly the purpose of a hash is to create some memory space, let say this memory space is 10 adresses big. with a hashmap, every value you put in the hashmap gets coupled with a key. that key will first be mapped by a hashfunction to produce a unique number. that number is within the range of possible adresses in the vector. $ f: a \\mapsto b $ with a the collection of possible keys and b a collection of possible adresses. mathematically speaking this is a mapping. the value gets then saved to that adress. now it is possible that you want to save more values than the vector allows or the hashfuntion is not completely one on one (that is every y has a unique x value it corresponds to) in that case you wil need to make the vector longer and remap every value within the vector or you reshash the value from the hashfunction with that same same value it has returned (usualy slightly edited to avoid all values being at the same place in the vector) as the parameter to find a new adress that wasn't used before. there are a number of other techniques involved and other methods but that is beside the point.\n",
      "long story short. this mapping of key values is, i believe, the reason it is called a hashmap.\n",
      "\n",
      "--------------------------------------------------Answer No:10--------------------------------------------------\n",
      "title :  mvc design, singleton in model with initialization\n",
      "\n",
      "\n",
      "question : i've recently learned of mvc (model view controller) and am trying to refactor an existing program.  i am in a situation where i'd like to have exactly one object of a particular class so it seemed evident that i should use a singleton.  this singleton will be used to keep a hashmap of certain things.  however this hashmap will have to be initialized when the singleton is created by reading nodes from a xml file and storing them as class objects.\n",
      "now my dilemma is:\n",
      "\n",
      "if i initialize the xml attributes (reading and converting to class objects), i'm effectively doing things in the model class that the controller should be doing, which is definitely not good. \n",
      "if i put the initialization method in a controller class, i would have to refer to a controller class from a model class, which does not conform to the mvc design.\n",
      "if i put the whole singleton in controller, then i'd have to look for the hashmap in the controller package, which defeats the purpose of having model classes.\n",
      "i can't pass a premade hashmap to the singleton as a parameter neither, because the constructor is private..  well, i technically could, by giving it to the getinstance() method as a parameter, but it feels like a dirty way of fixing, since i now either pass null every time, or make another getinstance() method that doesn't accept a  parameter.\n",
      "\n",
      "right now, my code is looking like this:\n",
      "public class categorycatalog{\n",
      "\n",
      "    private static categorycatalog categorycatalog;\n",
      "    private hashmap<caroptioncategory, set<icaroption>> categoryoptionsmap;\n",
      "\n",
      "    private categorycatalog(){\n",
      "        categoryoptionsmap = new hashmap<caroptioncategory, set<icaroption>>();\n",
      "        initialize();\n",
      "    }\n",
      "\n",
      "    public static categorycatalog getinstance(){\n",
      "        if(categorycatalog == null){\n",
      "            categorycatalog = new categorycatalog();\n",
      "        }\n",
      "        return categorycatalog;\n",
      "    }\n",
      "\n",
      "    private void initialize(){\n",
      "        // todo: xml\n",
      "    }\n",
      "}\n",
      "\n",
      "am i overlooking something or should i use a different approach?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "subanswer 1 : you have to use the right tool for the right problem. mvc is used to separate the representation logic from routing request logic (controller) and business logic (the model).\n",
      "for creating objects you should use creational patterns. now, in my opinion,\n",
      "\n",
      "if i initialize the xml attributes (reading and converting to class\n",
      "  objects), i'm effectively doing things in the model class that the\n",
      "  controller should be doing, which is definitely not good.\n",
      "\n",
      "it's good if the classes are used by the model.\n",
      "\n",
      "if i put the initialization method in a controller class, i would have\n",
      "  to refer to a controller class from a model class, which does not\n",
      "  conform to the mvc design.\n",
      "\n",
      "yep, don't do this because a low lever layer should not depend of a higher layer.\n",
      "\n",
      "if i put the whole singleton in controller, then i'd have to look for\n",
      "  the hashmap in the controller package, which defeats the purpose of\n",
      "  having model classes.\n",
      "\n",
      "this singleton is not a controller so don't do that too.\n",
      "\n",
      "i can't pass a premade hashmap to the singleton as a parameter\n",
      "  neither, because the constructor is private.. well, i technically\n",
      "  could, by giving it to the getinstance() method as a parameter, but it\n",
      "  feels like a dirty way of fixing, since i now either pass null every\n",
      "  time, or make another getinstance() method that doesn't accept a\n",
      "  parameter.\n",
      "\n",
      "yep, you will break encapsulation here because the hash map is an invariant of your class and if you accept a hash map it means that the invariant can be overwritten, maybe accidentally.\n",
      "in my opinion this singleton is some kind of factory that provides classes, if the classes are used by the model, then put this singleton in your model package. also take a look at spring, it will do this for you in a nice way.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# getting the combined search results both semantic and the text based.\n",
    "answer_no = 1\n",
    "for i in search(\"what is hashmap\"):\n",
    "    print('-'*50 + \"Answer No:\" + str(answer_no) + '-'*50)\n",
    "    title = total_text_dictionary[i[1]][0]\n",
    "    question = total_text_dictionary[i[1]][1]\n",
    "    print(\"title : \" ,title )\n",
    "    print('\\n')\n",
    "    print(\"question :\" , question)\n",
    "    print('\\n')\n",
    "    sub_answer = 1\n",
    "    for i in total_text_dictionary[i[1]][2:]:\n",
    "        print(\"subanswer \" + str(sub_answer) +' : ' + i )\n",
    "        sub_answer+=1\n",
    "    answer_no+=1\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert Embeddings Results_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------Answer No:1--------------------------------------------------\n",
      "title :  finding an element in a infinite unsorted doubly linked list\n",
      "\n",
      "\n",
      "question : is there any way to find an element in an unsorted doubly linked list given an element and pointer from which we can navigate? (we can't use head/tail pointers since the list is infinite)\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : infinite/unbounded in both directions?\n",
      "zig-zag.\n",
      "\n",
      "--------------------------------------------------Answer No:2--------------------------------------------------\n",
      "title :  a question about linked list\n",
      "\n",
      "\n",
      "question : i would like to check the answer of this exercise:\n",
      "a circular doubled linked list with n elements has pointers that cost k bytes each of space in memory. how many bytes do the pointers of this list cost in total?\n",
      "researching about circular linked lists, i can assume that each node has 2 pointers. so am i right to say that the answer is 2(n)k bytes?\n",
      "thanks.\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : the list takes $2*n*k$ bytes in total. a circular linked list is just a simple linked list with its last node's next pointer pointing back towards head. so, no extra pointer is required to make it circular. hence, the total space is $2*n*k$.\n",
      "\n",
      "--------------------------------------------------Answer No:3--------------------------------------------------\n",
      "title :  what's the advantage of two pointers linked list implementation of queue versus one pointer circular list\n",
      "\n",
      "\n",
      "question : princeton algorithms course shows the implementation of queue using linked list and two pointers - head and tail. i've implemented the same functionality as a circular linked list using only one pointer tail. i'm wondering what's the advantage of two pointers versus one in a circular list. it takes more space as i understand so why did they choose this implementation?\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : one possible advantage is that it is a little easier to understand how the push and pop operations work with a doubly-linked list.  the use of a singly-linked circular list is not that much harder to understand, but it is a trick, and at this stage where it's the first time you're seeing anything of the sort, any extra complication can be extra confusing.\n",
      "\n",
      "subanswer 2 : if you're not using a circular list, then you must have a pointer to head and tail to achieve $o(1)$ enqueue and dequeue. furthermore, if it is not a circular list and not a doubly-linked list, then without a pointer to head, we can't enqueue!\n",
      "some picture might help a little too.\n",
      "\n",
      "single linked list with only tail pointer:\n",
      "\n",
      "there's no way to get back to the head to enqueue! we would have to remedy this with a pointer to the head.\n",
      "doubly linked list with only tail pointer:\n",
      "\n",
      "we can get back to the head, but at an $o(n)$ cost, we might as well just add another pointer to head for convenience.\n",
      "single circular linked list with only tail pointer:\n",
      "\n",
      "we can get back to the head in $o(1)$! this is a good shortcut. in circular linked lists this node can sometimes implemented as a sentinel node which does not contain any information but works as a separator between the head and tail of the queue.\n",
      "\n",
      "in terms of additional space, adding tail or head or both is almost negligible. the nodes will be taking up memory no matter what, it's just whether or not you use a variable to reference them. using a circular linked list kind of acts like a head pointer if you think about it. tail.next would be a synonym for head, so it's not really saving space, nor is it really costing much space.\n",
      "\n",
      "--------------------------------------------------Answer No:4--------------------------------------------------\n",
      "title :  using singly linked list instead of a doubly linked list?\n",
      "\n",
      "\n",
      "question : are there advantages of implementing a singly instead of a doubly linked list other than space?\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : other than saving space, the first advantage i can see for singly\n",
      "linked lists over doubly linked lists is to avoid having to update two\n",
      "links instead of one when you modify the list, when adding an element\n",
      "for example.\n",
      "of course, one might say that you can always ignore the second link,\n",
      "but in that case, it is no longer doubly linked, but only an unused\n",
      "field.\n",
      "what might also be seen as an advantage is that singly linked list are\n",
      "necessarily consistent, though possibly wrong when there are bugs in\n",
      "the program.  doubly linked lists can end-up having inconsistent links\n",
      "forward and backward. but it is debatable which of the two cases, if\n",
      "any, is an advantage.\n",
      "update:\n",
      "i had tried to see some impact on garbage collection, but found\n",
      "none. actually, there is one when storage reclamation is done by\n",
      "reference counting, as reference counting is defeated by loops, and\n",
      "doubly linked lists contain loops. singly linked list escape the\n",
      "problem. of course, there are ways around it for doubly linked lists,\n",
      "such as the use of weak pointers, or programmable reference counting\n",
      "as part of data abstraction.\n",
      "\n",
      "subanswer 2 : yes. singly linked lists are easier to work with in highly concurrent situations, because there's less data to keep consistent.\n",
      "for example, suppose you want to append a lot of items to a linked list in a wait-free way. it's okay if consuming the items is not wait free, but producers absolutely must not block no matter what the other threads are doing.\n",
      "with a singly linked list you can just do:\n",
      "var newnode = new node(somevalue);\n",
      "var prevnode = interlocked.exchange(ref _insertionnode, newnode);\n",
      "prevnode.next = newnode; //note: next is volatile; this is a write-release\n",
      "\n",
      "easy! guaranteed progress for every producer. produced  nodes may not be immediately visible from the head of the list (a previous producer may have yet to update the next pointer of the node it got), but they eventually will be.\n",
      "with a doubly-linked list, you need cas loops and other try-retry-retry-fix-up sorts of constructs. it's a lot easier to make a mistake, so i won't try to just zip off an example.\n",
      "\n",
      "--------------------------------------------------Answer No:5--------------------------------------------------\n",
      "title :  does the head(start) pointer of doubly linked list points previously to the tail(last) node\n",
      "\n",
      "\n",
      "question : i have one question in my mind that in case of circular doubly linked list the head pointer of the doubly linked list also logically point to the next pointer of the tail node of the linked list and tail's next pointer also point to the previous pointer of head.\n",
      "please answer me this question i am a bit confused.\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : assume you have a circular doubly linked list with three nodes at position 1, 2 and 3:\n",
      "[1] next->2 prev->3\n",
      "[2] next->3 prev->1\n",
      "[3] next->1 prev->2\n",
      "\n",
      "in some sense there is no \"head\" and \"tail\" in a circular doubly linked list. though you will have a pointer outside as an entry point to access the list like head->1, which would be identical to 3:next->1.\n",
      "so the heads prev points to the \"tail\"\n",
      "the tails next points to the \"head\"\n",
      "\n",
      "subanswer 2 : it depends.\n",
      "is it a circular or linear list?\n",
      "if it's a circular list then there is no \"head\" or \"tail\" as each element's next and prev pointers will be set. you can start traversing the list anywhere and have to remember where you started so you know when to stop.\n",
      "if it's a linear list then the prev pointer of the head element will be null and the next pointer of the tail element will be null. you use this information to know when to stop.\n",
      "\n",
      "subanswer 3 : i've used a circular doubly linked list like this:\n",
      "typedef struct list {\n",
      "  struct list *next;\n",
      "  struct list *prev;\n",
      "  void *data;\n",
      "} list;\n",
      "\n",
      "i decided to define the head of a list as one that has data == null. so an empty list is one where next and prev point to itself and data == null. you can then insert before or after the head at will. you can iterate the list by starting at head->next and going till you hit head again.\n",
      "and here is the fun part: you can have multiple heads. nothing prevents you from inserting a second list with data == null. now there are two ways to iterate over the list: you can iterate till you hit the next head (data == null) or skip over heads and keep going till you hit the original head again.\n",
      "\n",
      "--------------------------------------------------Answer No:6--------------------------------------------------\n",
      "title :  building heaps and heapsort using linked list\n",
      "\n",
      "\n",
      "question : i know that linked list is not a appropriate data structure for building heaps but i am interested in knowing the time complexity of building heaps and heapsort using linked list.\n",
      "one of the answers here (https://stackoverflow.com/a/14584517/5841727) says that heap sort can be done in o(nlogn) using linked list which is same as with arrays.\n",
      "for building a heap, i think that heapify operation would cost  o(n) time in linked list and we would need (n/2) heapify operations leading to time complexity of o(n^2). is it correct?\n",
      "also, can someone please tell how to achieve o(nlogn) complexity (for heap sort ) using linked list ?\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : doubly linked list can be sorted by heapsort with o(nlogn) time, o(1) space complexity, but not singly linked-list.\n",
      "merge sort can apply to singly linked list with o(nlogn) time, o(n) space complexity.\n",
      "\n",
      "--------------------------------------------------Answer No:7--------------------------------------------------\n",
      "title :  linked list with merge sort\n",
      "\n",
      "\n",
      "question : is merge sort the best sorting technique to sort a linked list? also, which sorting technique is worst for a linked list?\n",
      "\n",
      "merge sort uses a divide and conquer method. what makes merge sort efficient for sorting a linked list?\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : it is really inefficient to access a certain index in a linked list, which is what many sorting algorithms rely on. mergesort, however, divides and merges lists, which lls do efficiently. you can find some code and an explanation here.\n",
      "\n",
      "--------------------------------------------------Answer No:8--------------------------------------------------\n",
      "title :  correct way to implement linked list\n",
      "\n",
      "\n",
      "question : i'm doing this challenge on hacker rank that wants me to implement a linked list.\n",
      "it seems to want me to find the last-added instance of node and change its head to link to my new instance of node. therefore the last instance added would have head=none (i'm using python).\n",
      "this is the pic they provide -\n",
      " \n",
      "wouldn't it make more sense to create a node instance with its head linked to the previous node? that way the only node with head=none would be the first node created.\n",
      "i've seen conflicting suggestions so far. i'm not a cs student or developer.\n",
      "edit -\n",
      "this example from youtube (1.36) suggests the second method.\n",
      "edit -\n",
      "sorry if this seemed like a programming question. i'm trying to see if there's a logical way to set up linked lists for my own benefit... solving the hackerrank challenge is not the issue.\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : one of the solutions can be:\n",
      "\n",
      "\n",
      "node* insert(node *head,int data)\n",
      "{\n",
      "node *p,*q;\n",
      "\n",
      "\n",
      "q=(struct node *)malloc(sizeof(struct node*));// allocating memory for new node\n",
      "if(q==null)\n",
      "{\n",
      "  printf(\"memory problem....\");  //return if memory can't be allocated\n",
      "  return 0;\n",
      "}\n",
      "q->data=data;                //put data in data portion of the new node\n",
      "q->next=null;                //the next link will point to null since it is getting added at the end of the list \n",
      "if(head == null)             //check out if the list is empty\n",
      "{\n",
      "    head=q;                  //if empty the new node will be 'head'\n",
      "}\n",
      "else\n",
      "{\n",
      "    p=head;\n",
      "    while(p->next != null)    // otherwise get to the end of the list\n",
      "    {\n",
      "        p=p->next;\n",
      "    }\n",
      "\n",
      "    p->next=q;                //last node of the list will point to the new node created\n",
      "\n",
      "}\n",
      " return head;                 \n",
      "\n",
      "}\n",
      "i have tested, it is working on hacker rank.\n",
      "whether the head is linked to previous or next it has to be singly linked list and we have to traverse to the end of the list for insertion of a node.\n",
      "i hope this is helpful to you....\n",
      "\n",
      "subanswer 2 : first of all, don't have a head pointer in your structure that doesn't point to the head of the list: it will confuse everyone. call the pointer in your structure next or something!\n",
      "you are right that in a singly-linked list (one with a next pointer but no pre pointer) it is illogical and inefficient to add new items to the end of the list. singly-linked lists work best when you add each new item to the beginning of the list. then all you need to do is:\n",
      "\n",
      "create a new item and fill in its data.\n",
      "set its next pointer to the value stored in the global head variable.\n",
      "set the global head variable to point to the new item.\n",
      "\n",
      "thus, as you say, only the first item to be added to the list will have next=null.\n",
      "adding items to the end of the list involves walking through the whole of the list every time, which is not efficient or sensible.\n",
      "if you wanted a singly linked list to which you could add items at the end, you would have a second global variable (call it tail) pointing to the last item in the list. this makes for inelegant code, since you now have different kinds of behaviour when tail is null (which it will be at the beginning) and when tail is not null. in fact, a good way of handling matters in this case is to create the list with one fictional item in it already, and tail pointing to that item. this saves a lot of tests, but you will of course have to remember, when walking through the list, not to pay attention to that fictional item.\n",
      "\n",
      "--------------------------------------------------Answer No:9--------------------------------------------------\n",
      "title :  using b-method, and formal methods in general, to model and verify a reverse linked list\n",
      "\n",
      "\n",
      "question : i am trying to do some formal modeling of a linked list, however instead of referencing the next block, each block needs to reference the previous block instead.\n",
      "is there already any formal methods or any formal for doing this ?\n",
      "exactly the same as a normal linked list but when a new block (value etc) is added this references the past value (much like the bitcoin blockchain).\n",
      "i have modeled a normal linked list (data queue) modeled in the b method \n",
      "machine dataqueue ( data , anydata , maxqueue )\n",
      "\n",
      "constraints anydata e data /\\ maxqueue > 0\n",
      "sees bool type\n",
      "sets token\n",
      "properties card ( token ) = maxqueue\n",
      "variables tokenseq , tokenmap\n",
      "\n",
      "invariant\n",
      "tokenseq e iseq ( token ) /\\\n",
      "tokenmap e token -|-> data /\\\n",
      "dom ( tokenmap )=  used\n",
      "initialisation\n",
      "tokenseq , tokenmap : [] , {}\n",
      "\n",
      "\n",
      "operations\n",
      "success , token <-- additem( item )  =^\n",
      "pre e item data then\n",
      "choice\n",
      "any new token where new_token  e token_used\n",
      "then\n",
      "tokenseq := tokenseq <-- new token ||\n",
      "tokenmap ( new token ) := item ||\n",
      "success , token := true , new token\n",
      "end\n",
      "or\n",
      "success := false || token :e token\n",
      "end\n",
      "end ;\n",
      "definitions\n",
      "used =^ ran ( tokenseq )\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : there are many approaches for verifying linked structures---arguably, more suitable than the b method---that you might want to use, depending on the language and properties you want to verify. most of the approaches rely on separation logic (which was in big part motivated for verification of linked structures).\n",
      "some tools include:\n",
      "\n",
      "full functional verification of linked data structures -- where you write java code with specifications in classical higher-order logic, while the verifier uses integrated reasoning of multiple different provers\n",
      "linked list, imperative separation logic in isabelle -- uses separation logic in isabelle theorem prover (other similar data structure examples might be found in the archive of formal proofs)\n",
      "dafny: a language and program verifier for functional correctness -- which allows specifying and verifying wide range of data structures in c# (many examples for linked lists exist, e.g. this one)\n",
      "\n",
      "to quote this answer (which answers a very similar question), even though you did not give details about what are you trying to verify, it seems that properties you might want to prove about the \"reverse linked list\" might be formulated as properties for a regular linked list. (if the reverse list requires some additional (non-standard) implementations, not already declared for the linked list, you might be able to model those in addition.)\n",
      "i am not sure what was the purpose of your example, but your code seems similar to an example of modelling a linked list with b (which includes other standard operations) method in program development by refinement case studies using the b method.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------Answer No:10--------------------------------------------------\n",
      "title :  question regarding linkedlist in java\n",
      "\n",
      "\n",
      "question : when i was reading a book for scjp, i came across the following paragraph.\n",
      "\n",
      "a linkedlist is ordered by index position, like arraylist, except that\n",
      "  the elements are doubly-linked to one another. this linkage gives you\n",
      "  new methods (beyond what you get from the list interface) for adding\n",
      "  and removing from the beginning or end, which makes it an easy choice\n",
      "  for implementing a stack or queue. keep in mind that a linkedlist may\n",
      "  iterate more slowly than an arraylist, but it's a good choice when you\n",
      "  need fast insertion and deletion..\n",
      "\n",
      "what makes a linkedlist to iterate more slowly than an arraylist ?\n",
      "\n",
      "\n",
      "\n",
      "subanswer 1 : here is an answer from stackoverflow that explains it pretty well:\n",
      "https://stackoverflow.com/questions/716597/array-or-list-in-java-which-is-faster\n",
      "basically, the arraylist is contiguous where the linkedlist is not.  incrementing to the next location in memory with the arraylist is considered faster than jumping to the next location via a reference in linkedlist.  also, maintenance of the linkedlist would incur overhead to maintain two sets of references for a doubly linked list.\n",
      "\n",
      "subanswer 2 : i haven't looked at these classes in java but typically an array will be faster than a linked list because in a linked list the list is made up of a series of nodes which each of a \"link\" to the next node in the sequence.  so when you ask for the 10th element it has to cycle through 10 elements to pull the one you want.  in an array (unless i'm mistaken) calling for an element takes you straight to that element.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# getting the combined search results both semantic and the text based.\n",
    "answer_no = 1\n",
    "for i in search(\"what is a linked list\"):\n",
    "    print('-'*50 + \"Answer No:\" + str(answer_no) + '-'*50)\n",
    "    title = total_text_dictionary[i[1]][0]\n",
    "    question = total_text_dictionary[i[1]][1]\n",
    "    print(\"title : \" ,title )\n",
    "    print('\\n')\n",
    "    print(\"question :\" , question)\n",
    "    print('\\n')\n",
    "    sub_answer = 1\n",
    "    for i in total_text_dictionary[i[1]][2:]:\n",
    "        print(\"subanswer \" + str(sub_answer) +' : ' + i )\n",
    "        sub_answer+=1\n",
    "    answer_no+=1\n",
    "end = time.time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
